{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载必备库文件\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon import data as gdata\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon.data.vision import transforms as gtransforms\n",
    "\n",
    "from gluoncv import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 步骤\n",
    "# 1. 读取样本和标注\n",
    "# 1. transform\n",
    "# 1. mini-batch 样本迭代器\n",
    "# 1. 定义 loss 以及 metric\n",
    "# 1. 定义网络结构并初始化权重\n",
    "# 1. 确定最优化方法\n",
    "# 1. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 损失函数\n",
    "l1_loss = gluon.loss.L1Loss()\n",
    "sigmoid_ce = gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n",
    "# 第一个参数是 pred ，第二个参数是 label\n",
    "softmax_ce = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 性能度量函数\n",
    "def metric_val(net, dataset_val, metric=None, ctx=mx.cpu(0)):\n",
    "    \n",
    "    if metric is None:\n",
    "        metric = mx.metric.Accuracy()\n",
    "        \n",
    "    for _, batch in enumerate(dataset_val):\n",
    "        # 将数据切片分别加载到不同的设备上\n",
    "        data_val = gluon.utils.split_and_load(batch[0], ctx, batch_axis=0)\n",
    "        label_val = gluon.utils.split_and_load(batch[1], ctx, batch_axis=0)\n",
    "        \n",
    "        yhat = [net(x) for x in data_val]\n",
    "        \n",
    "        # 第一个参数是 label ， 第二个参数是 output\n",
    "        metric.update(label_val, yhat)    \n",
    "  \n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.utils.metrics.coco_detection import COCODetectionMetric\n",
    "COCODetectionMetric??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.transforms import presets\n",
    "presets.yolo.YOLO3DefaultTrainTransform??\n",
    "presets.rcnn.FasterRCNNDefaultTrainTransform??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据预处理\n",
    "## 牢记 mxnet 使用 BCHW 形式\n",
    "\n",
    "# Dataset 类提供了两个转换函数： transform_first 和 transform ；\n",
    "# transform_first 只变换 data ； transform 同时变换样本和标签（一个样本的所有数据）\n",
    "\n",
    "# imgnet 数据集\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# 写两个函数，一个是 train_transform 一个 test_transform\n",
    "def train_transform(img, label, mean, std):\n",
    "    \"\"\"\n",
    "    YOLOv3 默认的数据预处理，图像和标签都需要处理\n",
    "    1. random color jittering\n",
    "    1. random expansion with prob 0.5\n",
    "    1. random cropping\n",
    "    1. resize with random interpolation\n",
    "    1. random horizontal flip\n",
    "    1. to tensor\n",
    "    1. nomalize\n",
    "    \"\"\"\n",
    "    \n",
    "    # random color jittering\n",
    "    mx.nd.image.random_color_jitter()\n",
    "    \n",
    "    # random expansion with prob 0.5\n",
    "    \n",
    "    # random cropping\n",
    "    mx.image.fixed_crop()\n",
    "    mx.image.random_crop()\n",
    "    \n",
    "    # resize with random interpolation\n",
    "    mx.image.imresize() # interp 利用入参进行了设置 (img, width, height, interp=interp)\n",
    "    \n",
    "    # random horizontal flip\n",
    "    mx.nd.image.random_flip_left_right()\n",
    "    \n",
    "    # to tensor WHC -> CHW\n",
    "    img = mx.nd.image.to_tensor(img)\n",
    "    \n",
    "    # nomalize\n",
    "    img = mx.nd.image.normalize(img, mean, std)\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def test_transform(img, lable, mean, std):\n",
    "    \n",
    "    # resize with random interpolation\n",
    "    mx.image.imresize() # interp 利用入参进行了设置 (img, width, height, interp=interp)\n",
    "    \n",
    "    # to tensor WHC -> CHW\n",
    "    img = mx.nd.image.to_tensor(img)\n",
    "    \n",
    "    # nomalize\n",
    "    img = mx.nd.image.normalize(img, mean, std)\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "\n",
    "# gluoncv 代码实现\n",
    "def transform(src, label, width, height, mean, std):\n",
    "    \"\"\"Apply transform to training image/label.\"\"\"\n",
    "    # random color jittering\n",
    "    img = experimental.image.random_color_distort(src)\n",
    "\n",
    "    # random expansion with prob 0.5\n",
    "    if np.random.uniform(0, 1) > 0.5:\n",
    "        img, expand = timage.random_expand(img, fill=[m * 255 for m in mean])\n",
    "        bbox = tbbox.translate(label, x_offset=expand[0], y_offset=expand[1])\n",
    "    else:\n",
    "        img, bbox = img, label\n",
    "\n",
    "    # random cropping\n",
    "    h, w, _ = img.shape\n",
    "    bbox, crop = experimental.bbox.random_crop_with_constraints(bbox, (w, h))\n",
    "    x0, y0, w, h = crop\n",
    "    img = mx.image.fixed_crop(img, x0, y0, w, h)\n",
    "\n",
    "    # resize with random interpolation\n",
    "    h, w, _ = img.shape\n",
    "    interp = np.random.randint(0, 5)\n",
    "    img = timage.imresize(img, width, height, interp=interp)\n",
    "    bbox = tbbox.resize(bbox, (w, h), (width, height))\n",
    "\n",
    "    # random horizontal flip\n",
    "    h, w, _ = img.shape\n",
    "    img, flips = timage.random_flip(img, px=0.5)\n",
    "    bbox = tbbox.flip(bbox, (w, h), flip_x=flips[0])\n",
    "\n",
    "    # to tensor\n",
    "    img = mx.nd.image.to_tensor(img)\n",
    "    img = mx.nd.image.normalize(img, mean=mean, std=std)\n",
    "\n",
    "    return img, bbox.astype(img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data import VOCDetection\n",
    "\n",
    "# typically we use 2007+2012 trainval splits for training data\n",
    "train_dataset = VOCDetection(root='/home/kyle/data/VOC/VOCdevkit/', splits=[(2007, 'trainval')])#, (2012, 'trainval')])\n",
    "# and use 2007 test as validation data\n",
    "val_dataset = VOCDetection(root='/home/kyle/data/VOC/VOCdevkit/', splits=[(2007, 'test')])\n",
    "\n",
    "print('Training images:', len(train_dataset))\n",
    "print('Validation images:', len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data import COCODetection\n",
    "train_dataset = COCODetection(root='~/data/coco', splits=['instances_train2017'], transform=None)\n",
    "val_dataset = COCODetection(root='~/data/coco', splits=['instances_val2017'], transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "\n",
    "\n",
    "def bbox_clip_xyxy(xyxy, width, height):\n",
    "    \"\"\"Clip bounding box with format (xmin, ymin, xmax, ymax) to specified boundary.\n",
    "\n",
    "    All bounding boxes will be clipped to the new region `(0, 0, width, height)`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyxy : list, tuple or numpy.ndarray\n",
    "        The bbox in format (xmin, ymin, xmax, ymax).\n",
    "        If numpy.ndarray is provided, we expect multiple bounding boxes with\n",
    "        shape `(N, 4)`.\n",
    "    width : int or float\n",
    "        Boundary width.\n",
    "    height : int or float\n",
    "        Boundary height.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    type\n",
    "        Description of returned object.\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(xyxy, (tuple, list)):\n",
    "        if not len(xyxy) == 4:\n",
    "            raise IndexError(\n",
    "                \"Bounding boxes must have 4 elements, given {}\".format(len(xyxy)))\n",
    "        x1 = np.minimum(width - 1, np.maximum(0, xyxy[0]))\n",
    "        y1 = np.minimum(height - 1, np.maximum(0, xyxy[1]))\n",
    "        x2 = np.minimum(width - 1, np.maximum(0, xyxy[2]))\n",
    "        y2 = np.minimum(height - 1, np.maximum(0, xyxy[3]))\n",
    "        return (x1, y1, x2, y2)\n",
    "    elif isinstance(xyxy, np.ndarray):\n",
    "        if not xyxy.size % 4 == 0:\n",
    "            raise IndexError(\n",
    "                \"Bounding boxes must have n * 4 elements, given {}\".format(xyxy.shape))\n",
    "        x1 = np.minimum(width - 1, np.maximum(0, xyxy[:, 0]))\n",
    "        y1 = np.minimum(height - 1, np.maximum(0, xyxy[:, 1]))\n",
    "        x2 = np.minimum(width - 1, np.maximum(0, xyxy[:, 2]))\n",
    "        y2 = np.minimum(height - 1, np.maximum(0, xyxy[:, 3]))\n",
    "        return np.hstack((x1, y1, x2, y2))\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            'Expect input xywh a list, tuple or numpy.ndarray, given {}'.format(type(xyxy)))\n",
    "\n",
    "def bbox_xywh_to_xyxy(xywh):\n",
    "    \"\"\"Convert bounding boxes from format (x, y, w, h) to (xmin, ymin, xmax, ymax)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xywh : list, tuple or numpy.ndarray\n",
    "        The bbox in format (x, y, w, h).\n",
    "        If numpy.ndarray is provided, we expect multiple bounding boxes with\n",
    "        shape `(N, 4)`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple or numpy.ndarray\n",
    "        The converted bboxes in format (xmin, ymin, xmax, ymax).\n",
    "        If input is numpy.ndarray, return is numpy.ndarray correspondingly.\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(xywh, (tuple, list)):\n",
    "        if not len(xywh) == 4:\n",
    "            raise IndexError(\n",
    "                \"Bounding boxes must have 4 elements, given {}\".format(len(xywh)))\n",
    "        w, h = np.maximum(xywh[2] - 1, 0), np.maximum(xywh[3] - 1, 0)\n",
    "        return (xywh[0], xywh[1], xywh[0] + w, xywh[1] + h)\n",
    "    elif isinstance(xywh, np.ndarray):\n",
    "        if not xywh.size % 4 == 0:\n",
    "            raise IndexError(\n",
    "                \"Bounding boxes must have n * 4 elements, given {}\".format(xywh.shape))\n",
    "        xyxy = np.hstack((xywh[:, :2], xywh[:, :2] + np.maximum(0, xywh[:, 2:4] - 1)))\n",
    "        return xyxy\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            'Expect input xywh a list, tuple or numpy.ndarray, given {}'.format(type(xywh)))\n",
    "\n",
    "\n",
    "class COCODetection():\n",
    "    \"\"\"MS COCO detection dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : str, default '~/mxnet/datasets/voc'\n",
    "        Path to folder storing the dataset.\n",
    "    splits : list of str, default ['instances_val2017']\n",
    "        Json annotations name.\n",
    "        Candidates can be: instances_val2017, instances_train2017.\n",
    "    transform : callable, defaut None\n",
    "        A function that takes data and label and transforms them. Refer to\n",
    "        :doc:`./transforms` for examples.\n",
    "\n",
    "        A transform function for object detection should take label into consideration,\n",
    "        because any geometric modification will require label to be modified.\n",
    "    min_object_area : float\n",
    "        Minimum accepted ground-truth area, if an object's area is smaller than this value,\n",
    "        it will be ignored.\n",
    "    skip_empty : bool, default is True\n",
    "        Whether skip images with no valid object. This should be `True` in training, otherwise\n",
    "        it will cause undefined behavior.\n",
    "    use_crowd : bool, default is True\n",
    "        Whether use boxes labeled as crowd instance.\n",
    "\n",
    "    \"\"\"\n",
    "    CLASSES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train',\n",
    "               'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "               'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "               'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "               'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "               'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
    "               'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "               'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "               'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n",
    "               'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "               'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "               'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "    def __init__(self, root=os.path.join('~', 'datasets', 'coco'),\n",
    "                 splits=('instances_val2017',), transform=None, min_object_area=0,\n",
    "                 skip_empty=True, use_crowd=True):\n",
    "        self._root = os.path.expanduser(root)\n",
    "        self._transform = transform\n",
    "        self._min_object_area = min_object_area\n",
    "        self._skip_empty = skip_empty\n",
    "        self._use_crowd = use_crowd\n",
    "        self.num_class = len(type(self).CLASSES)\n",
    "        if isinstance(splits, mx.base.string_types):\n",
    "            splits = [splits]\n",
    "        self._splits = splits\n",
    "        # to avoid trouble, we always use contiguous IDs except dealing with cocoapi\n",
    "        self.index_map = dict(zip(type(self).CLASSES, range(self.num_class)))\n",
    "        self.json_id_to_contiguous = None\n",
    "        self.contiguous_id_to_json = None\n",
    "        self._coco = []\n",
    "        self._items, self._labels = self._load_jsons()\n",
    "\n",
    "    def __str__(self):\n",
    "        detail = ','.join([str(s) for s in self._splits])\n",
    "        return self.__class__.__name__ + '(' + detail + ')'\n",
    "\n",
    "    @property\n",
    "    def coco(self):\n",
    "        \"\"\"Return pycocotools object for evaluation purposes.\"\"\"\n",
    "        if not self._coco:\n",
    "            raise ValueError(\"No coco objects found, dataset not initialized.\")\n",
    "        elif len(self._coco) > 1:\n",
    "            raise NotImplementedError(\n",
    "                \"Currently we don't support evaluating {} JSON files\".format(len(self._coco)))\n",
    "        return self._coco[0]\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        \"\"\"Category names.\"\"\"\n",
    "        return type(self).CLASSES\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self._items[idx]\n",
    "        label = self._labels[idx]\n",
    "        img = mx.image.imread(img_path, 1)\n",
    "        if self._transform is not None:\n",
    "            return self._transform(img, label)\n",
    "        return img, np.array(label)\n",
    "\n",
    "    def _load_jsons(self):\n",
    "        \"\"\"Load all image paths and labels from JSON annotation files into buffer.\"\"\"\n",
    "        items = []\n",
    "        labels = []\n",
    "        # lazy import pycocotools\n",
    "        from cocoapi.PythonAPI.pycocotools.coco import COCO\n",
    "        for split in self._splits:\n",
    "            anno = os.path.join(self._root, 'annotations', split) + '.json'\n",
    "            _coco = COCO(anno)\n",
    "            self._coco.append(_coco)\n",
    "            classes = [c['name'] for c in _coco.loadCats(_coco.getCatIds())]\n",
    "            if not classes == self.classes:\n",
    "                raise ValueError(\"Incompatible category names with COCO: \")\n",
    "            assert classes == self.classes\n",
    "            json_id_to_contiguous = {\n",
    "                v: k for k, v in enumerate(_coco.getCatIds())}\n",
    "            if self.json_id_to_contiguous is None:\n",
    "                self.json_id_to_contiguous = json_id_to_contiguous\n",
    "                self.contiguous_id_to_json = {\n",
    "                    v: k for k, v in self.json_id_to_contiguous.items()}\n",
    "            else:\n",
    "                assert self.json_id_to_contiguous == json_id_to_contiguous\n",
    "\n",
    "            # iterate through the annotations\n",
    "            image_ids = sorted(_coco.getImgIds())\n",
    "            for entry in _coco.loadImgs(image_ids):\n",
    "                dirname, filename = entry['coco_url'].split('/')[-2:]\n",
    "                abs_path = os.path.join(self._root, dirname, filename)\n",
    "                if not os.path.exists(abs_path):\n",
    "                    raise IOError('Image: {} not exists.'.format(abs_path))\n",
    "                label = self._check_load_bbox(_coco, entry)\n",
    "                if not label:\n",
    "                    continue\n",
    "                items.append(abs_path)\n",
    "                labels.append(label)\n",
    "        return items, labels\n",
    "\n",
    "    def _check_load_bbox(self, coco, entry):\n",
    "        \"\"\"Check and load ground-truth labels\"\"\"\n",
    "        ann_ids = coco.getAnnIds(imgIds=entry['id'], iscrowd=None)\n",
    "        objs = coco.loadAnns(ann_ids)\n",
    "        # check valid bboxes\n",
    "        valid_objs = []\n",
    "        width = entry['width']\n",
    "        height = entry['height']\n",
    "        for obj in objs:\n",
    "            if obj['area'] < self._min_object_area:\n",
    "                continue\n",
    "            if obj.get('ignore', 0) == 1:\n",
    "                continue\n",
    "            if not self._use_crowd and obj.get('iscrowd', 0):\n",
    "                continue\n",
    "            # convert from (x, y, w, h) to (xmin, ymin, xmax, ymax) and clip bound\n",
    "            xmin, ymin, xmax, ymax = bbox_clip_xyxy(bbox_xywh_to_xyxy(obj['bbox']), width, height)\n",
    "            # require non-zero box area\n",
    "            if obj['area'] > 0 and xmax > xmin and ymax > ymin:\n",
    "                contiguous_cid = self.json_id_to_contiguous[obj['category_id']]\n",
    "                valid_objs.append([xmin, ymin, xmax, ymax, contiguous_cid])\n",
    "        if not valid_objs:\n",
    "            if not self._skip_empty:\n",
    "                # dummy invalid labels if no valid objects are found\n",
    "                valid_objs.append([-1, -1, -1, -1, -1])\n",
    "        return valid_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = COCODetection(root='~/data/coco', splits=['instances_train2017'], transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据加载\n",
    "# from mxnet.gluon.data import DataLoader\n",
    "# 这个函数最主要实现的目的就是每次返回 batch_size 大小的样本 [ Loads data from a dataset and returns mini-batches of data. ]\n",
    "# 阅读 DataLoader 代码发现，这个函数就是先依据入参生成所有样本 batch_sampler (经过 shuffle 或者顺序读取)，\n",
    "# 然后生成一个迭代器，每次返回 batch_size 大小的样本，且会将这些样本进行函数 batchify_fn 处理 \n",
    "# 当然还可以使用多个线程同时读取，可以预先读取一定数量的样本等等\n",
    "# 可以自己去实现，但是感觉没有必要\n",
    "# 参数\n",
    "#    dataset : ndarray or numpy array\n",
    "#    batch_size : int\n",
    "#    shuffle : bool\n",
    "#    sampler : Sampler\n",
    "#    last_batch : {'keep', 'discard', 'rollover'}\n",
    "#    batch_sampler : Sampler\n",
    "#    batchify_fn : callable. 用户自定义组装样本的方法\n",
    "#    num_workers : int, default 0. 使用 num_workers 个线程来读取样本\n",
    "#    pin_memory : boolean, default False. 使用函数 mxnet.ndarray.ndarray.NDArray.as_in_context(context) 实现，加快从 CPU 到 GPU 的拷贝速度\n",
    "#    prefetch : int, default is `num_workers * 2`. 预处理样本的个数，会消耗较大的 shared_memory （应该是 GPU 的），当 num_workers > 0 时生效\n",
    "\n",
    "loader_train = DataLoader(voc_train.transform(transforms_train), \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True, \n",
    "                              last_batch='discard', \n",
    "                              num_workers=num_workers)\n",
    "\n",
    "loader_val = DataLoader(voc_val.transform(transforms_val),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False, \n",
    "                            num_workers=num_workers)\n",
    "\n",
    "for ib, batch in enumerate(loader_train):\n",
    "    if ib > 0:\n",
    "        break\n",
    "    print('data:', batch[0][0].shape)\n",
    "    print('label:', batch[6][0].shape)\n",
    "    # 将数据切片分别加载到不同的设备上 ； 始终卡在这里，下一条打印信息没有出来\n",
    "    data_train = gluon.utils.split_and_load(batch, ctx_list=ctx, batch_axis=0)\n",
    "    \n",
    "    print(\"aaa\")\n",
    "\n",
    "    with autograd.record():\n",
    "        input_order = [0, 6, 1, 2, 3, 4, 5]\n",
    "        obj_loss, center_loss, scale_loss, cls_loss = yolov3_model(*[data_train[o] for o in input_order])\n",
    "        # sum up the losses\n",
    "        # some standard gluon training steps:\n",
    "        # autograd.backward(sum_loss)\n",
    "        # trainer.step(batch_size)\n",
    "        print(\"bbb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.data import DataLoader\n",
    "DataLoader??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习参数\n",
    "# 调节学习速率衰减的倍数\n",
    "lr_decay = 0.1\n",
    "lr_decay_epochs_set = set([200, 400])\n",
    "\n",
    "def update_learn_rate(trainer, epoch, lr_decay_epochs_set, lr_decay=0.1):\n",
    "    if epoch in lr_decay_epochs_set:\n",
    "        trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "\n",
    "\n",
    "from gluoncv.utils import TrainingHistory\n",
    "train_history = TrainingHistory(['train', 'val'])\n",
    "\n",
    "\n",
    "# 最优化\n",
    "optimizer = mx.optimizer.Adam(learning_rate=0.0001,\n",
    "                             beta1=0.9,\n",
    "                             beta2=0.999,\n",
    "                             epsilon=1e-08,\n",
    "                             lazy_update=True)\n",
    "\n",
    "trainer = gluon.Trainer(yolov3_model.collect_params(), optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "gluon.Trainer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 冻结原有层的权重\n",
    "#resnet18_cifar10[0].collect_params().setattr('grad_req', 'null')\n",
    "## 初始化自定义层的权重\n",
    "#resnet18_cifar10[1].initialize(init=mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "## 网络训练\n",
    "def train_net(net, data_train, data_val, trainer, epochs):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #metric.reset()\n",
    "        train_loss = 0\n",
    "        update_learn_rate(trainer, epoch, lr_decay_epochs, lr_decay)\n",
    "        tic = time.time()\n",
    "        \n",
    "        # dataset 是可迭代对象\n",
    "        for i, batch in enumerate(loader_train):\n",
    "            # 将数据切片分别加载到不同的设备上；这里假如有 n 个 GPU ，前面的 DataLoader 中 batch_size 是不是应该是 batch*n ? TODO\n",
    "            data_train = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "            label_train = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
    "            \n",
    "            # 自动求导。record() 函数使得 mxnet 记录并计算梯度，需要训练的参数都需要计算梯度\n",
    "            with autograd.record():\n",
    "                output = [net(X) for X in data_train]\n",
    "                loss = [loss_fn(yhat, y) for yhat, y in zip(output, label_train)]\n",
    "\n",
    "            # loss 是 list ，当有多个 loss 的时候，所有的 loss 都需要反向传播\n",
    "            # l 是 mxnet.ndarray.ndarray.NDArray 格式的数据，本身就有 backward() 函数\n",
    "            # 调用 backward() 函数用于计算梯度\n",
    "            for l in loss:\n",
    "                l.backward()\n",
    "            \n",
    "            # 更新参数， 通过调用 allreduce_grads() 和 update() 来实现参数的更新\n",
    "            # 必须在 autograd.backward() 之后，以及 record() 之外调用\n",
    "            # allreduce_grads() 必须在 trainer.update() 之前调用\n",
    "            # 这里更新的时候是怎样用到上面计算的 loss 的？\n",
    "            # trainer 已经中指定了需要训练的参数，应该是可以在某个位置找到这些参数的梯度，从而使用指定的最优化方法来更新参数\n",
    "            trainer.step(batch_size)\n",
    "                        \n",
    "            for l in loss:\n",
    "                train_loss += l.sum().asscalar() / batch_size\n",
    "            \n",
    "            # 每个 batch 更新一下训练的准确率\n",
    "            metric.update(label_train, output)\n",
    "            \n",
    "        _, acc = metric.get()\n",
    "        _, val_acc = metric_val(net, dataset_val, ctx=ctx)\n",
    "        \n",
    "        # 这里记录的是错误率\n",
    "        train_history.update([1-acc, 1-val_acc])\n",
    "        \n",
    "        toc = time.time()\n",
    "        \n",
    "        print('[epoch %d] train_loss=%f, acc=%f, val_acc=%f, lr=%.9f, time: %fs' % \n",
    "              (epoch, train_loss, acc, val_acc, trainer.learning_rate, toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
