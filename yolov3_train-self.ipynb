{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载必备库文件\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon import data as gdata\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon.data.vision import transforms as gtransforms\n",
    "\n",
    "from gluoncv import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 步骤\n",
    "# 1. 读取样本和标注\n",
    "# 1. transform\n",
    "# 1. mini-batch 样本迭代器\n",
    "# 1. 定义 loss 以及 metric\n",
    "# 1. 定义网络结构并初始化权重\n",
    "# 1. 确定最优化方法\n",
    "# 1. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 所有需要调节的超参\n",
    "img_wight  = 416\n",
    "img_height = 416\n",
    "\n",
    "batch_size  = 2\n",
    "num_workers = 0\n",
    "\n",
    "# 学习参数\n",
    "# 调节学习速率衰减的倍数\n",
    "lr_decay = 0.1\n",
    "lr_decay_epochs_set = set([200, 400])\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "# number of GPUs to use\n",
    "num_gpus = 1\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定 epoch 时更新学习速率\n",
    "def update_learn_rate(trainer, epoch, lr_decay_epochs_set, lr_decay=0.1):\n",
    "    if epoch in lr_decay_epochs_set:\n",
    "        trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "\n",
    "# 最优化\n",
    "optimizer = mx.optimizer.Adam(learning_rate=0.0001,\n",
    "                             beta1=0.9,\n",
    "                             beta2=0.999,\n",
    "                             epsilon=1e-08,\n",
    "                             lazy_update=True)\n",
    "\n",
    "\n",
    "from gluoncv.utils import TrainingHistory\n",
    "train_history = TrainingHistory(['train', 'val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. obj_loss:    sum of objectness logistic loss\n",
    "1. center_loss: sum of box center logistic regression loss\n",
    "1. scale_loss:  sum of box scale l1 loss\n",
    "1. cls_loss:    sum of per class logistic loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 损失函数\n",
    "# l1_loss    = gluon.loss.L1Loss()\n",
    "# sigmoid_ce = gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n",
    "# # 第一个参数是 pred ，第二个参数是 label\n",
    "# softmax_ce = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "class YOLOV3Loss(gluon.loss.Loss):\n",
    "    \"\"\"Losses of YOLO v3.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_axis : int, default 0\n",
    "        The axis that represents mini-batch.\n",
    "    weight : float or None\n",
    "        Global scalar weight for loss.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_axis=0, weight=None, **kwargs):\n",
    "        super(YOLOV3Loss, self).__init__(weight, batch_axis, **kwargs)\n",
    "        self._sigmoid_ce = gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n",
    "        self._l1_loss = gluon.loss.L1Loss()\n",
    "\n",
    "    def hybrid_forward(self, F, objness, box_centers, box_scales, cls_preds,\n",
    "                       objness_t, center_t, scale_t, weight_t, class_t, class_mask):\n",
    "        \"\"\"Compute YOLOv3 losses.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        objness : mxnet.nd.NDArray\n",
    "            Predicted objectness (B, N), range (0, 1).\n",
    "        box_centers : mxnet.nd.NDArray\n",
    "            Predicted box centers (x, y) (B, N, 2), range (0, 1).\n",
    "        box_scales : mxnet.nd.NDArray\n",
    "            Predicted box scales (width, height) (B, N, 2).\n",
    "        cls_preds : mxnet.nd.NDArray\n",
    "            Predicted class predictions (B, N, num_class), range (0, 1).\n",
    "        objness_t : mxnet.nd.NDArray\n",
    "            Objectness target, (B, N), 0 for negative 1 for positive, -1 for ignore.\n",
    "        center_t : mxnet.nd.NDArray\n",
    "            Center (x, y) targets (B, N, 2).\n",
    "        scale_t : mxnet.nd.NDArray\n",
    "            Scale (width, height) targets (B, N, 2).\n",
    "        weight_t : mxnet.nd.NDArray\n",
    "            Loss Multipliers for center and scale targets (B, N, 2).\n",
    "        class_t : mxnet.nd.NDArray\n",
    "            Class targets (B, N, num_class).\n",
    "            It's relaxed one-hot vector, i.e., (1, 0, 1, 0, 0).\n",
    "            It can contain more than one positive class.\n",
    "        class_mask : mxnet.nd.NDArray\n",
    "            0 or 1 mask array to mask out ignored samples (B, N, num_class).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple of NDArrays\n",
    "            obj_loss: sum of objectness logistic loss\n",
    "            center_loss: sum of box center logistic regression loss\n",
    "            scale_loss: sum of box scale l1 loss\n",
    "            cls_loss: sum of per class logistic loss\n",
    "\n",
    "        \"\"\"\n",
    "        # compute some normalization count, except batch-size\n",
    "        denorm = F.cast(\n",
    "            F.shape_array(objness_t).slice_axis(axis=0, begin=1, end=None).prod(), 'float32')\n",
    "        weight_t = F.broadcast_mul(weight_t, objness_t)\n",
    "        hard_objness_t = F.where(objness_t > 0, F.ones_like(objness_t), objness_t)\n",
    "        new_objness_mask = F.where(objness_t > 0, objness_t, objness_t >= 0)\n",
    "        obj_loss = F.broadcast_mul(\n",
    "            self._sigmoid_ce(objness, hard_objness_t, new_objness_mask), denorm)\n",
    "        center_loss = F.broadcast_mul(self._sigmoid_ce(box_centers, center_t, weight_t), denorm * 2)\n",
    "        scale_loss = F.broadcast_mul(self._l1_loss(box_scales, scale_t, weight_t), denorm * 2)\n",
    "        denorm_class = F.cast(\n",
    "            F.shape_array(class_t).slice_axis(axis=0, begin=1, end=None).prod(), 'float32')\n",
    "        class_mask = F.broadcast_mul(class_mask, objness_t)\n",
    "        cls_loss = F.broadcast_mul(self._sigmoid_ce(cls_preds, class_t, class_mask), denorm_class)\n",
    "        return obj_loss, center_loss, scale_loss, cls_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 性能度量函数\n",
    "def metric_val(net, dataset_val, metric=None, ctx=mx.cpu(0)):\n",
    "    \n",
    "    if metric is None:\n",
    "        metric = mx.metric.Accuracy()\n",
    "        \n",
    "    for _, batch in enumerate(dataset_val):\n",
    "        # 将数据切片分别加载到不同的设备上\n",
    "        data_val = gluon.utils.split_and_load(batch[0], ctx, batch_axis=0)\n",
    "        label_val = gluon.utils.split_and_load(batch[1], ctx, batch_axis=0)\n",
    "        \n",
    "        yhat = [net(x) for x in data_val]\n",
    "        \n",
    "        # 第一个参数是 label ， 第二个参数是 output\n",
    "        metric.update(label_val, yhat)    \n",
    "  \n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.utils.metrics.coco_detection import COCODetectionMetric\n",
    "COCODetectionMetric??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCODetectionMetric(mx.metric.EvalMetric):\n",
    "    \"\"\"Detection metric for COCO bbox task.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : instance of gluoncv.data.COCODetection\n",
    "        The validation dataset.\n",
    "    save_prefix : str\n",
    "        Prefix for the saved JSON results.\n",
    "    use_time : bool\n",
    "        Append unique datetime string to created JSON file name if ``True``.\n",
    "    cleanup : bool\n",
    "        Remove created JSON file if ``True``.\n",
    "    score_thresh : float\n",
    "        Detection results with confident scores smaller than ``score_thresh`` will\n",
    "        be discarded before saving to results.\n",
    "    data_shape : tuple of int, default is None\n",
    "        If `data_shape` is provided as (height, width), we will rescale bounding boxes when\n",
    "        saving the predictions.\n",
    "        This is helpful when SSD/YOLO box predictions cannot be rescaled conveniently. Note that\n",
    "        the data_shape must be fixed for all validation images.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, save_prefix, use_time=True, cleanup=False, score_thresh=0.05,\n",
    "                 data_shape=None):\n",
    "        super(COCODetectionMetric, self).__init__('COCOMeanAP')\n",
    "        self.dataset = dataset\n",
    "        self._img_ids = sorted(dataset.coco.getImgIds())\n",
    "        self._current_id = 0\n",
    "        self._cleanup = cleanup\n",
    "        self._results = []\n",
    "        self._score_thresh = score_thresh\n",
    "        if isinstance(data_shape, (tuple, list)):\n",
    "            assert len(data_shape) == 2, \"Data shape must be (height, width)\"\n",
    "        elif not data_shape:\n",
    "            data_shape = None\n",
    "        else:\n",
    "            raise ValueError(\"data_shape must be None or tuple of int as (height, width)\")\n",
    "        self._data_shape = data_shape\n",
    "\n",
    "        if use_time:\n",
    "            import datetime\n",
    "            t = datetime.datetime.now().strftime('_%Y_%m_%d_%H_%M_%S')\n",
    "        else:\n",
    "            t = ''\n",
    "        self._filename = osp.abspath(osp.expanduser(save_prefix) + t + '.json')\n",
    "        try:\n",
    "            f = open(self._filename, 'w')\n",
    "        except IOError as e:\n",
    "            raise RuntimeError(\"Unable to open json file to dump. What(): {}\".format(str(e)))\n",
    "        else:\n",
    "            f.close()\n",
    "\n",
    "    def __del__(self):\n",
    "        if self._cleanup:\n",
    "            try:\n",
    "                os.remove(self._filename)\n",
    "            except IOError as err:\n",
    "                warnings.warn(str(err))\n",
    "\n",
    "    def reset(self):\n",
    "        self._current_id = 0\n",
    "        self._results = []\n",
    "\n",
    "    def _update(self):\n",
    "        \"\"\"Use coco to get real scores. \"\"\"\n",
    "        if not self._current_id == len(self._img_ids):\n",
    "            warnings.warn(\n",
    "                'Recorded {} out of {} validation images, incompelete results'.format(\n",
    "                    self._current_id, len(self._img_ids)))\n",
    "        import json\n",
    "        try:\n",
    "            with open(self._filename, 'w') as f:\n",
    "                json.dump(self._results, f)\n",
    "        except IOError as e:\n",
    "            raise RuntimeError(\"Unable to dump json file, ignored. What(): {}\".format(str(e)))\n",
    "\n",
    "        pred = self.dataset.coco.loadRes(self._filename)\n",
    "        gt = self.dataset.coco\n",
    "        # lazy import pycocotools\n",
    "        try_import_pycocotools()\n",
    "        from pycocotools.cocoeval import COCOeval\n",
    "        coco_eval = COCOeval(gt, pred, 'bbox')\n",
    "        coco_eval.evaluate()\n",
    "        coco_eval.accumulate()\n",
    "        self._coco_eval = coco_eval\n",
    "        return coco_eval\n",
    "\n",
    "    def get(self):\n",
    "        \"\"\"Get evaluation metrics. \"\"\"\n",
    "        # Metric printing adapted from detectron/json_dataset_evaluator.\n",
    "        def _get_thr_ind(coco_eval, thr):\n",
    "            ind = np.where((coco_eval.params.iouThrs > thr - 1e-5) &\n",
    "                           (coco_eval.params.iouThrs < thr + 1e-5))[0][0]\n",
    "            iou_thr = coco_eval.params.iouThrs[ind]\n",
    "            assert np.isclose(iou_thr, thr)\n",
    "            return ind\n",
    "\n",
    "        # call real update\n",
    "        coco_eval = self._update()\n",
    "\n",
    "        IoU_lo_thresh = 0.5\n",
    "        IoU_hi_thresh = 0.95\n",
    "        ind_lo = _get_thr_ind(coco_eval, IoU_lo_thresh)\n",
    "        ind_hi = _get_thr_ind(coco_eval, IoU_hi_thresh)\n",
    "        # precision has dims (iou, recall, cls, area range, max dets)\n",
    "        # area range index 0: all area ranges\n",
    "        # max dets index 2: 100 per image\n",
    "        precision = coco_eval.eval['precision'][ind_lo:(ind_hi + 1), :, :, 0, 2]\n",
    "        ap_default = np.mean(precision[precision > -1])\n",
    "        names, values = [], []\n",
    "        names.append('~~~~ Summary metrics ~~~~\\n')\n",
    "        # catch coco print string, don't want directly print here\n",
    "        _stdout = sys.stdout\n",
    "        sys.stdout = StringIO()\n",
    "        coco_eval.summarize()\n",
    "        coco_summary = sys.stdout.getvalue()\n",
    "        sys.stdout = _stdout\n",
    "        values.append(str(coco_summary).strip())\n",
    "        for cls_ind, cls_name in enumerate(self.dataset.classes):\n",
    "            precision = coco_eval.eval['precision'][\n",
    "                ind_lo:(ind_hi + 1), :, cls_ind, 0, 2]\n",
    "            ap = np.mean(precision[precision > -1])\n",
    "            names.append(cls_name)\n",
    "            values.append('{:.1f}'.format(100 * ap))\n",
    "        # put mean AP at last, for comparing perf\n",
    "        names.append('~~~~ MeanAP @ IoU=[{:.2f},{:.2f}] ~~~~\\n'.format(\n",
    "            IoU_lo_thresh, IoU_hi_thresh))\n",
    "        values.append('{:.1f}'.format(100 * ap_default))\n",
    "        return names, values\n",
    "\n",
    "    # pylint: disable=arguments-differ, unused-argument\n",
    "    def update(self, pred_bboxes, pred_labels, pred_scores, *args, **kwargs):\n",
    "        \"\"\"Update internal buffer with latest predictions.\n",
    "        Note that the statistics are not available until you call self.get() to return\n",
    "        the metrics.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pred_bboxes : mxnet.NDArray or numpy.ndarray\n",
    "            Prediction bounding boxes with shape `B, N, 4`.\n",
    "            Where B is the size of mini-batch, N is the number of bboxes.\n",
    "        pred_labels : mxnet.NDArray or numpy.ndarray\n",
    "            Prediction bounding boxes labels with shape `B, N`.\n",
    "        pred_scores : mxnet.NDArray or numpy.ndarray\n",
    "            Prediction bounding boxes scores with shape `B, N`.\n",
    "\n",
    "        \"\"\"\n",
    "        def as_numpy(a):\n",
    "            \"\"\"Convert a (list of) mx.NDArray into numpy.ndarray\"\"\"\n",
    "            if isinstance(a, (list, tuple)):\n",
    "                out = [x.asnumpy() if isinstance(x, mx.nd.NDArray) else x for x in a]\n",
    "                return np.concatenate(out, axis=0)\n",
    "            elif isinstance(a, mx.nd.NDArray):\n",
    "                a = a.asnumpy()\n",
    "            return a\n",
    "\n",
    "        for pred_bbox, pred_label, pred_score in zip(\n",
    "                *[as_numpy(x) for x in [pred_bboxes, pred_labels, pred_scores]]):\n",
    "            valid_pred = np.where(pred_label.flat >= 0)[0]\n",
    "            pred_bbox = pred_bbox[valid_pred, :].astype(np.float)\n",
    "            pred_label = pred_label.flat[valid_pred].astype(int)\n",
    "            pred_score = pred_score.flat[valid_pred].astype(np.float)\n",
    "\n",
    "            imgid = self._img_ids[self._current_id]\n",
    "            self._current_id += 1\n",
    "            if self._data_shape is not None:\n",
    "                entry = self.dataset.coco.loadImgs(imgid)[0]\n",
    "                orig_height = entry['height']\n",
    "                orig_width = entry['width']\n",
    "                height_scale = float(orig_height) / self._data_shape[0]\n",
    "                width_scale = float(orig_width) / self._data_shape[1]\n",
    "            else:\n",
    "                height_scale, width_scale = (1., 1.)\n",
    "            # for each bbox detection in each image\n",
    "            for bbox, label, score in zip(pred_bbox, pred_label, pred_score):\n",
    "                if label not in self.dataset.contiguous_id_to_json:\n",
    "                    # ignore non-exist class\n",
    "                    continue\n",
    "                if score < self._score_thresh:\n",
    "                    continue\n",
    "                category_id = self.dataset.contiguous_id_to_json[label]\n",
    "                # rescale bboxes\n",
    "                bbox[[0, 2]] *= width_scale\n",
    "                bbox[[1, 3]] *= height_scale\n",
    "                # convert [xmin, ymin, xmax, ymax]  to [xmin, ymin, w, h]\n",
    "                bbox[2:4] -= (bbox[:2] - 1)\n",
    "                self._results.append({'image_id': imgid,\n",
    "                                      'category_id': category_id,\n",
    "                                      'bbox': bbox[:4].tolist(),\n",
    "                                      'score': score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 暂时不进行额外的 trainsfrom ，只进行 resize 操作\n",
    "class ValTransform(object):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    width : int\n",
    "        Image width.\n",
    "    height : int\n",
    "        Image height.\n",
    "    mean : array-like of size 3\n",
    "        Mean pixel values to be subtracted from image tensor. Default is [0.485, 0.456, 0.406].\n",
    "    std : array-like of size 3\n",
    "        Standard deviation to be divided from image. Default is [0.229, 0.224, 0.225].\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, width, height, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "        self._width = width\n",
    "        self._height = height\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def __call__(self, src, label):\n",
    "        \"\"\"Apply transform to validation image/label.\"\"\"\n",
    "        # resize\n",
    "        h, w, _ = src.shape\n",
    "        img = mx.image.imresize(src, self._width, self._height, interp=9)\n",
    "        bbox = self.bbox_resize(label, in_size=(w, h), out_size=(self._width, self._height))\n",
    "\n",
    "        img = mx.nd.image.to_tensor(img)\n",
    "        img = mx.nd.image.normalize(img, mean=self._mean, std=self._std)\n",
    "        return img, bbox.astype(img.dtype)\n",
    "\n",
    "    def bbox_resize(bbox, in_size, out_size):\n",
    "        \"\"\"Resize bouding boxes according to image resize operation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bbox : numpy.ndarray\n",
    "            :math:`(x_{min}, y_{min}, x_{max}, y_{max})`,\n",
    "        in_size : tuple\n",
    "            Tuple of length 2: (width, height) for input.\n",
    "        out_size : tuple\n",
    "            Tuple of length 2: (width, height) for output.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Resized bounding boxes with original shape.\n",
    "        \"\"\"\n",
    "\n",
    "        bbox = bbox.copy()\n",
    "        x_scale = out_size[0] / in_size[0]\n",
    "        y_scale = out_size[1] / in_size[1]\n",
    "        bbox[:, 1] = y_scale * bbox[:, 1]\n",
    "        bbox[:, 3] = y_scale * bbox[:, 3]\n",
    "        bbox[:, 0] = x_scale * bbox[:, 0]\n",
    "        bbox[:, 2] = x_scale * bbox[:, 2]\n",
    "        return bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_clip_xyxy(xyxy, width, height):\n",
    "    \"\"\"Clip bounding box with format (xmin, ymin, xmax, ymax) to specified boundary.\n",
    "\n",
    "    All bounding boxes will be clipped to the new region `(0, 0, width, height)`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyxy : list, tuple or numpy.ndarray\n",
    "        The bbox in format (xmin, ymin, xmax, ymax).\n",
    "        If numpy.ndarray is provided, we expect multiple bounding boxes with\n",
    "        shape `(N, 4)`.\n",
    "    width : int or float\n",
    "        Boundary width.\n",
    "    height : int or float\n",
    "        Boundary height.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    type\n",
    "        Description of returned object.\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(xyxy, (tuple, list)):\n",
    "        if not len(xyxy) == 4:\n",
    "            raise IndexError(\n",
    "                \"Bounding boxes must have 4 elements, given {}\".format(len(xyxy)))\n",
    "        x1 = np.minimum(width - 1, np.maximum(0, xyxy[0]))\n",
    "        y1 = np.minimum(height - 1, np.maximum(0, xyxy[1]))\n",
    "        x2 = np.minimum(width - 1, np.maximum(0, xyxy[2]))\n",
    "        y2 = np.minimum(height - 1, np.maximum(0, xyxy[3]))\n",
    "        return (x1, y1, x2, y2)\n",
    "    elif isinstance(xyxy, np.ndarray):\n",
    "        if not xyxy.size % 4 == 0:\n",
    "            raise IndexError(\n",
    "                \"Bounding boxes must have n * 4 elements, given {}\".format(xyxy.shape))\n",
    "        x1 = np.minimum(width - 1, np.maximum(0, xyxy[:, 0]))\n",
    "        y1 = np.minimum(height - 1, np.maximum(0, xyxy[:, 1]))\n",
    "        x2 = np.minimum(width - 1, np.maximum(0, xyxy[:, 2]))\n",
    "        y2 = np.minimum(height - 1, np.maximum(0, xyxy[:, 3]))\n",
    "        return np.hstack((x1, y1, x2, y2))\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            'Expect input xywh a list, tuple or numpy.ndarray, given {}'.format(type(xyxy)))\n",
    "\n",
    "def bbox_xywh_to_xyxy(xywh):\n",
    "    \"\"\"Convert bounding boxes from format (x, y, w, h) to (xmin, ymin, xmax, ymax)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xywh : list, tuple or numpy.ndarray\n",
    "        The bbox in format (x, y, w, h).\n",
    "        If numpy.ndarray is provided, we expect multiple bounding boxes with\n",
    "        shape `(N, 4)`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple or numpy.ndarray\n",
    "        The converted bboxes in format (xmin, ymin, xmax, ymax).\n",
    "        If input is numpy.ndarray, return is numpy.ndarray correspondingly.\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(xywh, (tuple, list)):\n",
    "        if not len(xywh) == 4:\n",
    "            raise IndexError(\n",
    "                \"Bounding boxes must have 4 elements, given {}\".format(len(xywh)))\n",
    "        w, h = np.maximum(xywh[2] - 1, 0), np.maximum(xywh[3] - 1, 0)\n",
    "        return (xywh[0], xywh[1], xywh[0] + w, xywh[1] + h)\n",
    "    elif isinstance(xywh, np.ndarray):\n",
    "        if not xywh.size % 4 == 0:\n",
    "            raise IndexError(\n",
    "                \"Bounding boxes must have n * 4 elements, given {}\".format(xywh.shape))\n",
    "        xyxy = np.hstack((xywh[:, :2], xywh[:, :2] + np.maximum(0, xywh[:, 2:4] - 1)))\n",
    "        return xyxy\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            'Expect input xywh a list, tuple or numpy.ndarray, given {}'.format(type(xywh)))\n",
    "\n",
    "\n",
    "class LoadCOCO(object):\n",
    "    \"\"\"MS COCO detection dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : str, default '~/mxnet/datasets/coco'\n",
    "        Path to folder storing the dataset.\n",
    "    splits : list of str, default ['instances_val2017']\n",
    "        Json annotations name.\n",
    "        Candidates can be: instances_val2017, instances_train2017.\n",
    "    transform : callable, defaut None\n",
    "        A function that takes data and label and transforms them. Refer to\n",
    "        :doc:`./transforms` for examples.\n",
    "\n",
    "        A transform function for object detection should take label into consideration,\n",
    "        because any geometric modification will require label to be modified.\n",
    "    min_object_area : float\n",
    "        Minimum accepted ground-truth area\n",
    "    skip_empty : bool, default is True\n",
    "        Whether skip images with no valid object. This should be `True` in training, otherwise\n",
    "        it will cause undefined behavior.\n",
    "    use_crowd : bool, default is True\n",
    "        Whether use boxes labeled as crowd instance.\n",
    "\n",
    "    \"\"\"\n",
    "    CLASSES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train',\n",
    "               'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "               'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "               'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "               'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "               'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
    "               'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "               'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "               'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n",
    "               'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "               'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "               'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "    def __init__(self, root=os.path.join('~', 'datasets', 'coco'),\n",
    "                 splits=('instances_val2017',), transform=None, min_object_area=0,\n",
    "                 skip_empty=True, use_crowd=True):\n",
    "        self._root = os.path.expanduser(root)\n",
    "        self._transform = transform\n",
    "        self._min_object_area = min_object_area\n",
    "        self._skip_empty = skip_empty\n",
    "        self._use_crowd = use_crowd\n",
    "        self.num_class = len(type(self).CLASSES)\n",
    "        if isinstance(splits, mx.base.string_types):\n",
    "            splits = [splits]\n",
    "        self._splits = splits\n",
    "        # to avoid trouble, we always use contiguous IDs except dealing with cocoapi\n",
    "        self.index_map = dict(zip(type(self).CLASSES, range(self.num_class)))\n",
    "        self.json_id_to_contiguous = None\n",
    "        self.contiguous_id_to_json = None\n",
    "        self._coco = []\n",
    "        self._items, self._labels = self._load_jsons()\n",
    "\n",
    "    def __str__(self):\n",
    "        detail = ','.join([str(s) for s in self._splits])\n",
    "        return self.__class__.__name__ + '(' + detail + ')'\n",
    "\n",
    "    @property\n",
    "    def coco(self):\n",
    "        \"\"\"Return pycocotools object for evaluation purposes.\"\"\"\n",
    "        if not self._coco:\n",
    "            raise ValueError(\"No coco objects found, dataset not initialized.\")\n",
    "        elif len(self._coco) > 1:\n",
    "            raise NotImplementedError(\n",
    "                \"Currently we don't support evaluating {} JSON files\".format(len(self._coco)))\n",
    "        return self._coco[0]\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        \"\"\"Category names.\"\"\"\n",
    "        return type(self).CLASSES\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self._items[idx]\n",
    "        label = self._labels[idx]\n",
    "        img = mx.image.imread(img_path, 1)\n",
    "        if self._transform is not None:\n",
    "            return self._transform(img, label)\n",
    "        return img, np.array(label)\n",
    "\n",
    "    def _load_jsons(self):\n",
    "        \"\"\"Load all image paths and labels from JSON annotation files into buffer.\"\"\"\n",
    "        items = []\n",
    "        labels = []\n",
    "        # lazy import pycocotools\n",
    "        from cocoapi.PythonAPI.pycocotools.coco import COCO\n",
    "        for split in self._splits:\n",
    "            anno = os.path.join(self._root, 'annotations', split) + '.json'\n",
    "            _coco = COCO(anno)\n",
    "            self._coco.append(_coco)\n",
    "            classes = [c['name'] for c in _coco.loadCats(_coco.getCatIds())]\n",
    "            if not classes == self.classes:\n",
    "                raise ValueError(\"Incompatible category names with COCO: \")\n",
    "            assert classes == self.classes\n",
    "            json_id_to_contiguous = {\n",
    "                v: k for k, v in enumerate(_coco.getCatIds())}\n",
    "            if self.json_id_to_contiguous is None:\n",
    "                self.json_id_to_contiguous = json_id_to_contiguous\n",
    "                self.contiguous_id_to_json = {\n",
    "                    v: k for k, v in self.json_id_to_contiguous.items()}\n",
    "            else:\n",
    "                assert self.json_id_to_contiguous == json_id_to_contiguous\n",
    "\n",
    "            # iterate through the annotations\n",
    "            image_ids = sorted(_coco.getImgIds())\n",
    "            for entry in _coco.loadImgs(image_ids):\n",
    "                dirname, filename = entry['coco_url'].split('/')[-2:]\n",
    "                abs_path = os.path.join(self._root, dirname, filename)\n",
    "                if not os.path.exists(abs_path):\n",
    "                    raise IOError('Image: {} not exists.'.format(abs_path))\n",
    "                label = self._check_load_bbox(_coco, entry)\n",
    "                if not label:\n",
    "                    continue\n",
    "                items.append(abs_path)\n",
    "                labels.append(label)\n",
    "        return items, labels\n",
    "\n",
    "    def _check_load_bbox(self, coco, entry):\n",
    "        \"\"\"Check and load ground-truth labels\"\"\"\n",
    "        ann_ids = coco.getAnnIds(imgIds=entry['id'], iscrowd=None)\n",
    "        objs = coco.loadAnns(ann_ids)\n",
    "        # check valid bboxes\n",
    "        valid_objs = []\n",
    "        width = entry['width']\n",
    "        height = entry['height']\n",
    "        for obj in objs:\n",
    "            if obj['area'] < self._min_object_area:\n",
    "                continue\n",
    "            if obj.get('ignore', 0) == 1:\n",
    "                continue\n",
    "            if not self._use_crowd and obj.get('iscrowd', 0):\n",
    "                continue\n",
    "            # convert from (x, y, w, h) to (xmin, ymin, xmax, ymax) and clip bound\n",
    "            xmin, ymin, xmax, ymax = bbox_clip_xyxy(bbox_xywh_to_xyxy(obj['bbox']), width, height)\n",
    "            # require non-zero box area\n",
    "            if obj['area'] > 0 and xmax > xmin and ymax > ymin:\n",
    "                contiguous_cid = self.json_id_to_contiguous[obj['category_id']]\n",
    "                valid_objs.append([xmin, ymin, xmax, ymax, contiguous_cid])\n",
    "        if not valid_objs:\n",
    "            if not self._skip_empty:\n",
    "                # dummy invalid labels if no valid objects are found\n",
    "                valid_objs.append([-1, -1, -1, -1, -1])\n",
    "        return valid_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.31s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# 内存太小，只能使用验证集进行 fine-tune\n",
    "#train_dataset = LoadCOCO(root='~/data/coco', splits=['instances_train2017'], transform=None)\n",
    "#val_dataset = LoadCOCO(root='~/data/coco', splits=['instances_val2017'], transform=ValTransform(img_wight, img_height))\n",
    "val_dataset = LoadCOCO(root='~/data/coco', splits=['instances_val2017'], transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4952\n"
     ]
    }
   ],
   "source": [
    "print(len(val_dataset))\n",
    "loader_train = DataLoader(val_dataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True, \n",
    "                              last_batch='discard', \n",
    "                              num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "<class 'numpy.object_'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e790a2d9829a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#batch = loader_train[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#data, label = gluon.utils.split_and_load()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mib\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36msame_process_iter\u001b[0;34m()\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0msame_process_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_sampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batchify_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_pinned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_batchify_fn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_batchify_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_batchify_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_batchify_fn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/utils.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(source_array, ctx, dtype)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sparse_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(source_array, ctx, dtype)\u001b[0m\n\u001b[1;32m   2493\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2494\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'source_array must be array like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2495\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2496\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2497\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36mempty\u001b[0;34m(shape, ctx, dtype)\u001b[0m\n\u001b[1;32m   3882\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3883\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx_real_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3884\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_new_alloc_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36m_new_alloc_handle\u001b[0;34m(shape, ctx, delay_alloc, dtype)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay_alloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DTYPE_NP_TO_MX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         ctypes.byref(hdl)))\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: <class 'numpy.object_'>"
     ]
    }
   ],
   "source": [
    "#batch = loader_train[0]\n",
    "#data, label = gluon.utils.split_and_load()\n",
    "for ib, batch in enumerate(loader_train):\n",
    "    if ib > 0:\n",
    "        break\n",
    "    print('data:', batch[0][0].shape)\n",
    "    print('label:', batch[6][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ib, batch in enumerate(loader_train):\n",
    "    if ib > 0:\n",
    "        break\n",
    "    print('data:', batch[0][0].shape)\n",
    "    print('label:', batch[6][0].shape)\n",
    "    # 将数据切片分别加载到不同的设备上 ； 始终卡在这里，下一条打印信息没有出来\n",
    "    data_train = gluon.utils.split_and_load(batch, ctx_list=ctx, batch_axis=0)\n",
    "    \n",
    "    print(\"aaa\")\n",
    "\n",
    "    with autograd.record():\n",
    "        input_order = [0, 6, 1, 2, 3, 4, 5]\n",
    "        obj_loss, center_loss, scale_loss, cls_loss = yolov3_model(*[data_train[o] for o in input_order])\n",
    "        # sum up the losses\n",
    "        # some standard gluon training steps:\n",
    "        # autograd.backward(sum_loss)\n",
    "        # trainer.step(batch_size)\n",
    "        print(\"bbb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据加载\n",
    "# from mxnet.gluon.data import DataLoader\n",
    "# 这个函数最主要实现的目的就是每次返回 batch_size 大小的样本 [ Loads data from a dataset and returns mini-batches of data. ]\n",
    "# 阅读 DataLoader 代码发现，这个函数就是先依据入参生成所有样本 batch_sampler (经过 shuffle 或者顺序读取)，\n",
    "# 然后生成一个迭代器，每次返回 batch_size 大小的样本，且会将这些样本进行函数 batchify_fn 处理 \n",
    "# 当然还可以使用多个线程同时读取，可以预先读取一定数量的样本等等\n",
    "# 可以自己去实现，但是感觉没有必要\n",
    "# 参数\n",
    "#    dataset : ndarray or numpy array. 应该是经过 transform 之后的数据\n",
    "#    batch_size : int\n",
    "#    shuffle : bool\n",
    "#    sampler : Sampler\n",
    "#    last_batch : {'keep', 'discard', 'rollover'}\n",
    "#    batch_sampler : Sampler\n",
    "#    batchify_fn : callable. 用户自定义组装样本的方法\n",
    "#    num_workers : int, default 0. 使用 num_workers 个线程来读取样本\n",
    "#    pin_memory : boolean, default False. 使用函数 mxnet.ndarray.ndarray.NDArray.as_in_context(context) 实现，加快从 CPU 到 GPU 的拷贝速度\n",
    "#    prefetch : int, default is `num_workers * 2`. 预处理样本的个数，会消耗较大的 shared_memory （应该是 GPU 的），当 num_workers > 0 时生效\n",
    "\n",
    "loader_train = DataLoader(val_dataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True, \n",
    "                              last_batch='discard', \n",
    "                              num_workers=num_workers)\n",
    "\n",
    "loader_val = DataLoader(val_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False, \n",
    "                            num_workers=num_workers)\n",
    "\n",
    "for ib, batch in enumerate(loader_train):\n",
    "    if ib > 0:\n",
    "        break\n",
    "    print('data:', batch[0][0].shape)\n",
    "    print('label:', batch[6][0].shape)\n",
    "    # 将数据切片分别加载到不同的设备上 ； 始终卡在这里，下一条打印信息没有出来\n",
    "    data_train = gluon.utils.split_and_load(batch, ctx_list=ctx, batch_axis=0)\n",
    "    \n",
    "    print(\"aaa\")\n",
    "\n",
    "    with autograd.record():\n",
    "        input_order = [0, 6, 1, 2, 3, 4, 5]\n",
    "        obj_loss, center_loss, scale_loss, cls_loss = yolov3_model(*[data_train[o] for o in input_order])\n",
    "        # sum up the losses\n",
    "        # some standard gluon training steps:\n",
    "        # autograd.backward(sum_loss)\n",
    "        # trainer.step(batch_size)\n",
    "        print(\"bbb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gluon.Trainer 使用指定的最优化方法来更新参数\n",
    "trainer = gluon.Trainer(yolov3_model.collect_params(), optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 冻结原有层的权重\n",
    "#resnet18_cifar10[0].collect_params().setattr('grad_req', 'null')\n",
    "## 初始化自定义层的权重\n",
    "#resnet18_cifar10[1].initialize(init=mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 网络训练\n",
    "def train_net(net, data_train, data_val, trainer, epochs):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #metric.reset()\n",
    "        train_loss = 0\n",
    "        update_learn_rate(trainer, epoch, lr_decay_epochs, lr_decay)\n",
    "        tic = time.time()\n",
    "        \n",
    "        # dataset 是可迭代对象\n",
    "        for i, batch in enumerate(loader_train):\n",
    "            # 将数据切片分别加载到不同的设备上；\n",
    "            # 假如有 n 个 GPU ，前面的 DataLoader 中 batch_size 是不是应该是 batch*n ? TODO\n",
    "            data_train = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "            label_train = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
    "            \n",
    "            # 自动求导: record() 函数使得 mxnet 记录并计算梯度，需要训练的参数都需要计算梯度\n",
    "            with autograd.record():\n",
    "                output = [net(X) for X in data_train]\n",
    "                loss = [loss_fn(yhat, y) for yhat, y in zip(output, label_train)]\n",
    "\n",
    "            # loss 是 list ，当有多个 loss 的时候，所有的 loss 都需要反向传播\n",
    "            # l 是 mxnet.ndarray.ndarray.NDArray 格式的数据，本身就有 backward() 函数\n",
    "            # 调用 backward() 函数用于计算梯度\n",
    "            for l in loss:\n",
    "                l.backward()\n",
    "            \n",
    "            # 更新参数， 通过调用 allreduce_grads() 和 update() 来实现参数的更新\n",
    "            # 必须在 autograd.backward() 之后，以及 record() 之外调用\n",
    "            # allreduce_grads() 必须在 trainer.update() 之前调用\n",
    "            # 这里更新的时候是怎样用到上面计算的 loss 的？\n",
    "            # trainer 已经中指定了需要训练的参数，应该是可以在某个位置找到这些参数的梯度，从而使用指定的最优化方法来更新参数\n",
    "            trainer.step(batch_size)\n",
    "                        \n",
    "            for l in loss:\n",
    "                train_loss += l.sum().asscalar() / batch_size\n",
    "            \n",
    "            # 每个 batch 更新一下训练的准确率\n",
    "            metric.update(label_train, output)\n",
    "            \n",
    "        _, acc = metric.get()\n",
    "        _, val_acc = metric_val(net, dataset_val, ctx=ctx)\n",
    "        \n",
    "        # 这里记录的是错误率\n",
    "        train_history.update([1-acc, 1-val_acc])\n",
    "        \n",
    "        toc = time.time()\n",
    "        \n",
    "        print('[epoch %d] train_loss=%f, acc=%f, val_acc=%f, lr=%.9f, time: %fs' % \n",
    "              (epoch, train_loss, acc, val_acc, trainer.learning_rate, toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gluoncv 提供的 transform 函数\n",
    "#from gluoncv.data.transforms import presets\n",
    "#presets.yolo.YOLO3DefaultTrainTransform\n",
    "#presets.rcnn.FasterRCNNDefaultTrainTransform\n",
    "\n",
    "## 数据预处理\n",
    "## 牢记 mxnet 使用 BCHW 形式\n",
    "\n",
    "# Dataset 类提供了两个转换函数： transform_first 和 transform ；\n",
    "# transform_first 只变换 data ； transform 同时变换样本和标签（一个样本的所有数据）\n",
    "\n",
    "# imgnet 数据集\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# 写两个函数，一个是 train_transform 一个 test_transform\n",
    "def train_transform(img, label, mean, std):\n",
    "    \"\"\"\n",
    "    YOLOv3 默认的数据预处理，图像和标签都需要处理\n",
    "    1. random color jittering\n",
    "    1. random expansion with prob 0.5\n",
    "    1. random cropping\n",
    "    1. resize with random interpolation\n",
    "    1. random horizontal flip\n",
    "    1. to tensor\n",
    "    1. nomalize\n",
    "    \"\"\"\n",
    "    \n",
    "    # random color jittering\n",
    "    mx.nd.image.random_color_jitter()\n",
    "    \n",
    "    # random expansion with prob 0.5\n",
    "    \n",
    "    # random cropping\n",
    "    mx.image.fixed_crop()\n",
    "    mx.image.random_crop()\n",
    "    \n",
    "    # resize with random interpolation\n",
    "    mx.image.imresize() # interp 利用入参进行了设置 (img, width, height, interp=interp)\n",
    "    \n",
    "    # random horizontal flip\n",
    "    mx.nd.image.random_flip_left_right()\n",
    "    \n",
    "    # to tensor WHC -> CHW\n",
    "    img = mx.nd.image.to_tensor(img)\n",
    "    \n",
    "    # nomalize\n",
    "    img = mx.nd.image.normalize(img, mean, std)\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def test_transform(img, lable, mean, std):\n",
    "    \n",
    "    # resize with random interpolation\n",
    "    mx.image.imresize() # interp 利用入参进行了设置 (img, width, height, interp=interp)\n",
    "    \n",
    "    # to tensor WHC -> CHW\n",
    "    img = mx.nd.image.to_tensor(img)\n",
    "    \n",
    "    # nomalize\n",
    "    img = mx.nd.image.normalize(img, mean, std)\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "\n",
    "# gluoncv 代码实现\n",
    "def transform(src, label, width, height, mean, std):\n",
    "    \"\"\"Apply transform to training image/label.\"\"\"\n",
    "    # random color jittering\n",
    "    img = experimental.image.random_color_distort(src)\n",
    "\n",
    "    # random expansion with prob 0.5\n",
    "    if np.random.uniform(0, 1) > 0.5:\n",
    "        img, expand = timage.random_expand(img, fill=[m * 255 for m in mean])\n",
    "        bbox = tbbox.translate(label, x_offset=expand[0], y_offset=expand[1])\n",
    "    else:\n",
    "        img, bbox = img, label\n",
    "\n",
    "    # random cropping\n",
    "    h, w, _ = img.shape\n",
    "    bbox, crop = experimental.bbox.random_crop_with_constraints(bbox, (w, h))\n",
    "    x0, y0, w, h = crop\n",
    "    img = mx.image.fixed_crop(img, x0, y0, w, h)\n",
    "\n",
    "    # resize with random interpolation\n",
    "    h, w, _ = img.shape\n",
    "    interp = np.random.randint(0, 5)\n",
    "    img = timage.imresize(img, width, height, interp=interp)\n",
    "    bbox = tbbox.resize(bbox, (w, h), (width, height))\n",
    "\n",
    "    # random horizontal flip\n",
    "    h, w, _ = img.shape\n",
    "    img, flips = timage.random_flip(img, px=0.5)\n",
    "    bbox = tbbox.flip(bbox, (w, h), flip_x=flips[0])\n",
    "\n",
    "    # to tensor\n",
    "    img = mx.nd.image.to_tensor(img)\n",
    "    img = mx.nd.image.normalize(img, mean=mean, std=std)\n",
    "\n",
    "    return img, bbox.astype(img.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
