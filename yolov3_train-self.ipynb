{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载必备库文件\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon import data as gdata\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon.data.vision import transforms as gtransforms\n",
    "\n",
    "from gluoncv import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 步骤\n",
    "# 1. 读取样本和标注\n",
    "# 1. transform\n",
    "# 1. mini-batch 样本迭代器\n",
    "# 1. 定义 loss 以及 metric\n",
    "# 1. 定义网络结构并初始化权重\n",
    "# 1. 确定最优化方法\n",
    "# 1. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 所有需要调节的超参\n",
    "img_wight  = 416\n",
    "img_height = 416\n",
    "\n",
    "batch_size  = 128\n",
    "num_workers = 0\n",
    "\n",
    "# 学习参数\n",
    "# 调节学习速率衰减的倍数\n",
    "lr_decay = 0.1\n",
    "lr_decay_epochs_set = set([200, 400])\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "# number of GPUs to use\n",
    "num_gpus = 1\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定 epoch 时更新学习速率\n",
    "def update_learn_rate(trainer, epoch, lr_decay_epochs_set, lr_decay=0.1):\n",
    "    if epoch in lr_decay_epochs_set:\n",
    "        trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "\n",
    "# 最优化\n",
    "optimizer = mx.optimizer.Adam(learning_rate=0.0001,\n",
    "                             beta1=0.9,\n",
    "                             beta2=0.999,\n",
    "                             epsilon=1e-08,\n",
    "                             lazy_update=True)\n",
    "\n",
    "\n",
    "from gluoncv.utils import TrainingHistory\n",
    "train_history = TrainingHistory(['train', 'val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. obj_loss:    sum of objectness logistic loss\n",
    "1. center_loss: sum of box center logistic regression loss\n",
    "1. scale_loss:  sum of box scale l1 loss\n",
    "1. cls_loss:    sum of per class logistic loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 损失函数\n",
    "# l1_loss    = gluon.loss.L1Loss()\n",
    "# sigmoid_ce = gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n",
    "# # 第一个参数是 pred ，第二个参数是 label\n",
    "# softmax_ce = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "class YOLOV3Loss(gluon.loss.Loss):\n",
    "    \"\"\"Losses of YOLO v3.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_axis : int, default 0\n",
    "        The axis that represents mini-batch.\n",
    "    weight : float or None\n",
    "        Global scalar weight for loss.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_axis=0, weight=None, **kwargs):\n",
    "        super(YOLOV3Loss, self).__init__(weight, batch_axis, **kwargs)\n",
    "        self._sigmoid_ce = gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n",
    "        self._l1_loss = gluon.loss.L1Loss()\n",
    "\n",
    "    def hybrid_forward(self, F, objness, box_centers, box_scales, cls_preds,\n",
    "                       objness_t, center_t, scale_t, weight_t, class_t, class_mask):\n",
    "        \"\"\"Compute YOLOv3 losses.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        objness : mxnet.nd.NDArray\n",
    "            Predicted objectness (B, N), range (0, 1).\n",
    "        box_centers : mxnet.nd.NDArray\n",
    "            Predicted box centers (x, y) (B, N, 2), range (0, 1).\n",
    "        box_scales : mxnet.nd.NDArray\n",
    "            Predicted box scales (width, height) (B, N, 2).\n",
    "        cls_preds : mxnet.nd.NDArray\n",
    "            Predicted class predictions (B, N, num_class), range (0, 1).\n",
    "        objness_t : mxnet.nd.NDArray\n",
    "            Objectness target, (B, N), 0 for negative 1 for positive, -1 for ignore.\n",
    "        center_t : mxnet.nd.NDArray\n",
    "            Center (x, y) targets (B, N, 2).\n",
    "        scale_t : mxnet.nd.NDArray\n",
    "            Scale (width, height) targets (B, N, 2).\n",
    "        weight_t : mxnet.nd.NDArray\n",
    "            Loss Multipliers for center and scale targets (B, N, 2).\n",
    "        class_t : mxnet.nd.NDArray\n",
    "            Class targets (B, N, num_class).\n",
    "            It's relaxed one-hot vector, i.e., (1, 0, 1, 0, 0).\n",
    "            It can contain more than one positive class.\n",
    "        class_mask : mxnet.nd.NDArray\n",
    "            0 or 1 mask array to mask out ignored samples (B, N, num_class).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple of NDArrays\n",
    "            obj_loss: sum of objectness logistic loss\n",
    "            center_loss: sum of box center logistic regression loss\n",
    "            scale_loss: sum of box scale l1 loss\n",
    "            cls_loss: sum of per class logistic loss\n",
    "\n",
    "        \"\"\"\n",
    "        # compute some normalization count, except batch-size\n",
    "        denorm = F.cast(\n",
    "            F.shape_array(objness_t).slice_axis(axis=0, begin=1, end=None).prod(), 'float32')\n",
    "        weight_t = F.broadcast_mul(weight_t, objness_t)\n",
    "        hard_objness_t = F.where(objness_t > 0, F.ones_like(objness_t), objness_t)\n",
    "        new_objness_mask = F.where(objness_t > 0, objness_t, objness_t >= 0)\n",
    "        obj_loss = F.broadcast_mul(\n",
    "            self._sigmoid_ce(objness, hard_objness_t, new_objness_mask), denorm)\n",
    "        center_loss = F.broadcast_mul(self._sigmoid_ce(box_centers, center_t, weight_t), denorm * 2)\n",
    "        scale_loss = F.broadcast_mul(self._l1_loss(box_scales, scale_t, weight_t), denorm * 2)\n",
    "        denorm_class = F.cast(\n",
    "            F.shape_array(class_t).slice_axis(axis=0, begin=1, end=None).prod(), 'float32')\n",
    "        class_mask = F.broadcast_mul(class_mask, objness_t)\n",
    "        cls_loss = F.broadcast_mul(self._sigmoid_ce(cls_preds, class_t, class_mask), denorm_class)\n",
    "        return obj_loss, center_loss, scale_loss, cls_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gluoncv.utils.metrics.coco_detection import COCODetectionMetric\n",
    "class COCODetectionMetric(mx.metric.EvalMetric):\n",
    "    \"\"\"Detection metric for COCO bbox task.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : instance of gluoncv.data.COCODetection\n",
    "        The validation dataset.\n",
    "    save_prefix : str\n",
    "        Prefix for the saved JSON results.\n",
    "    use_time : bool\n",
    "        Append unique datetime string to created JSON file name if ``True``.\n",
    "    cleanup : bool\n",
    "        Remove created JSON file if ``True``.\n",
    "    score_thresh : float\n",
    "        Detection results with confident scores smaller than ``score_thresh`` will\n",
    "        be discarded before saving to results.\n",
    "    data_shape : tuple of int, default is None\n",
    "        If `data_shape` is provided as (height, width), we will rescale bounding boxes when\n",
    "        saving the predictions.\n",
    "        This is helpful when SSD/YOLO box predictions cannot be rescaled conveniently. Note that\n",
    "        the data_shape must be fixed for all validation images.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, save_prefix, use_time=True, cleanup=False, score_thresh=0.05,\n",
    "                 data_shape=None):\n",
    "        super(COCODetectionMetric, self).__init__('COCOMeanAP')\n",
    "        self.dataset = dataset\n",
    "        self._img_ids = sorted(dataset.coco.getImgIds())\n",
    "        self._current_id = 0\n",
    "        self._cleanup = cleanup\n",
    "        self._results = []\n",
    "        self._score_thresh = score_thresh\n",
    "        if isinstance(data_shape, (tuple, list)):\n",
    "            assert len(data_shape) == 2, \"Data shape must be (height, width)\"\n",
    "        elif not data_shape:\n",
    "            data_shape = None\n",
    "        else:\n",
    "            raise ValueError(\"data_shape must be None or tuple of int as (height, width)\")\n",
    "        self._data_shape = data_shape\n",
    "\n",
    "        if use_time:\n",
    "            import datetime\n",
    "            t = datetime.datetime.now().strftime('_%Y_%m_%d_%H_%M_%S')\n",
    "        else:\n",
    "            t = ''\n",
    "        self._filename = osp.abspath(osp.expanduser(save_prefix) + t + '.json')\n",
    "        try:\n",
    "            f = open(self._filename, 'w')\n",
    "        except IOError as e:\n",
    "            raise RuntimeError(\"Unable to open json file to dump. What(): {}\".format(str(e)))\n",
    "        else:\n",
    "            f.close()\n",
    "\n",
    "    def __del__(self):\n",
    "        if self._cleanup:\n",
    "            try:\n",
    "                os.remove(self._filename)\n",
    "            except IOError as err:\n",
    "                warnings.warn(str(err))\n",
    "\n",
    "    def reset(self):\n",
    "        self._current_id = 0\n",
    "        self._results = []\n",
    "\n",
    "    def _update(self):\n",
    "        \"\"\"Use coco to get real scores. \"\"\"\n",
    "        if not self._current_id == len(self._img_ids):\n",
    "            warnings.warn(\n",
    "                'Recorded {} out of {} validation images, incompelete results'.format(\n",
    "                    self._current_id, len(self._img_ids)))\n",
    "        import json\n",
    "        try:\n",
    "            with open(self._filename, 'w') as f:\n",
    "                json.dump(self._results, f)\n",
    "        except IOError as e:\n",
    "            raise RuntimeError(\"Unable to dump json file, ignored. What(): {}\".format(str(e)))\n",
    "\n",
    "        pred = self.dataset.coco.loadRes(self._filename)\n",
    "        gt = self.dataset.coco\n",
    "        # lazy import pycocotools\n",
    "        try_import_pycocotools()\n",
    "        from pycocotools.cocoeval import COCOeval\n",
    "        coco_eval = COCOeval(gt, pred, 'bbox')\n",
    "        coco_eval.evaluate()\n",
    "        coco_eval.accumulate()\n",
    "        self._coco_eval = coco_eval\n",
    "        return coco_eval\n",
    "\n",
    "    def get(self):\n",
    "        \"\"\"Get evaluation metrics. \"\"\"\n",
    "        # Metric printing adapted from detectron/json_dataset_evaluator.\n",
    "        def _get_thr_ind(coco_eval, thr):\n",
    "            ind = np.where((coco_eval.params.iouThrs > thr - 1e-5) &\n",
    "                           (coco_eval.params.iouThrs < thr + 1e-5))[0][0]\n",
    "            iou_thr = coco_eval.params.iouThrs[ind]\n",
    "            assert np.isclose(iou_thr, thr)\n",
    "            return ind\n",
    "\n",
    "        # call real update\n",
    "        coco_eval = self._update()\n",
    "\n",
    "        IoU_lo_thresh = 0.5\n",
    "        IoU_hi_thresh = 0.95\n",
    "        ind_lo = _get_thr_ind(coco_eval, IoU_lo_thresh)\n",
    "        ind_hi = _get_thr_ind(coco_eval, IoU_hi_thresh)\n",
    "        # precision has dims (iou, recall, cls, area range, max dets)\n",
    "        # area range index 0: all area ranges\n",
    "        # max dets index 2: 100 per image\n",
    "        precision = coco_eval.eval['precision'][ind_lo:(ind_hi + 1), :, :, 0, 2]\n",
    "        ap_default = np.mean(precision[precision > -1])\n",
    "        names, values = [], []\n",
    "        names.append('~~~~ Summary metrics ~~~~\\n')\n",
    "        # catch coco print string, don't want directly print here\n",
    "        _stdout = sys.stdout\n",
    "        sys.stdout = StringIO()\n",
    "        coco_eval.summarize()\n",
    "        coco_summary = sys.stdout.getvalue()\n",
    "        sys.stdout = _stdout\n",
    "        values.append(str(coco_summary).strip())\n",
    "        for cls_ind, cls_name in enumerate(self.dataset.classes):\n",
    "            precision = coco_eval.eval['precision'][\n",
    "                ind_lo:(ind_hi + 1), :, cls_ind, 0, 2]\n",
    "            ap = np.mean(precision[precision > -1])\n",
    "            names.append(cls_name)\n",
    "            values.append('{:.1f}'.format(100 * ap))\n",
    "        # put mean AP at last, for comparing perf\n",
    "        names.append('~~~~ MeanAP @ IoU=[{:.2f},{:.2f}] ~~~~\\n'.format(\n",
    "            IoU_lo_thresh, IoU_hi_thresh))\n",
    "        values.append('{:.1f}'.format(100 * ap_default))\n",
    "        return names, values\n",
    "\n",
    "    # pylint: disable=arguments-differ, unused-argument\n",
    "    def update(self, pred_bboxes, pred_labels, pred_scores, *args, **kwargs):\n",
    "        \"\"\"Update internal buffer with latest predictions.\n",
    "        Note that the statistics are not available until you call self.get() to return\n",
    "        the metrics.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pred_bboxes : mxnet.NDArray or numpy.ndarray\n",
    "            Prediction bounding boxes with shape `B, N, 4`.\n",
    "            Where B is the size of mini-batch, N is the number of bboxes.\n",
    "        pred_labels : mxnet.NDArray or numpy.ndarray\n",
    "            Prediction bounding boxes labels with shape `B, N`.\n",
    "        pred_scores : mxnet.NDArray or numpy.ndarray\n",
    "            Prediction bounding boxes scores with shape `B, N`.\n",
    "\n",
    "        \"\"\"\n",
    "        def as_numpy(a):\n",
    "            \"\"\"Convert a (list of) mx.NDArray into numpy.ndarray\"\"\"\n",
    "            if isinstance(a, (list, tuple)):\n",
    "                out = [x.asnumpy() if isinstance(x, mx.nd.NDArray) else x for x in a]\n",
    "                return np.concatenate(out, axis=0)\n",
    "            elif isinstance(a, mx.nd.NDArray):\n",
    "                a = a.asnumpy()\n",
    "            return a\n",
    "\n",
    "        for pred_bbox, pred_label, pred_score in zip(\n",
    "                *[as_numpy(x) for x in [pred_bboxes, pred_labels, pred_scores]]):\n",
    "            valid_pred = np.where(pred_label.flat >= 0)[0]\n",
    "            pred_bbox = pred_bbox[valid_pred, :].astype(np.float)\n",
    "            pred_label = pred_label.flat[valid_pred].astype(int)\n",
    "            pred_score = pred_score.flat[valid_pred].astype(np.float)\n",
    "\n",
    "            imgid = self._img_ids[self._current_id]\n",
    "            self._current_id += 1\n",
    "            if self._data_shape is not None:\n",
    "                entry = self.dataset.coco.loadImgs(imgid)[0]\n",
    "                orig_height = entry['height']\n",
    "                orig_width = entry['width']\n",
    "                height_scale = float(orig_height) / self._data_shape[0]\n",
    "                width_scale = float(orig_width) / self._data_shape[1]\n",
    "            else:\n",
    "                height_scale, width_scale = (1., 1.)\n",
    "            # for each bbox detection in each image\n",
    "            for bbox, label, score in zip(pred_bbox, pred_label, pred_score):\n",
    "                if label not in self.dataset.contiguous_id_to_json:\n",
    "                    # ignore non-exist class\n",
    "                    continue\n",
    "                if score < self._score_thresh:\n",
    "                    continue\n",
    "                category_id = self.dataset.contiguous_id_to_json[label]\n",
    "                # rescale bboxes\n",
    "                bbox[[0, 2]] *= width_scale\n",
    "                bbox[[1, 3]] *= height_scale\n",
    "                # convert [xmin, ymin, xmax, ymax]  to [xmin, ymin, w, h]\n",
    "                bbox[2:4] -= (bbox[:2] - 1)\n",
    "                self._results.append({'image_id': imgid,\n",
    "                                      'category_id': category_id,\n",
    "                                      'bbox': bbox[:4].tolist(),\n",
    "                                      'score': score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 暂时不进行额外的 trainsfrom ，只进行 resize 操作\n",
    "class ValTransform(object):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    width : int\n",
    "        Image width.\n",
    "    height : int\n",
    "        Image height.\n",
    "    mean : array-like of size 3\n",
    "        Mean pixel values to be subtracted from image tensor. Default is [0.485, 0.456, 0.406].\n",
    "    std : array-like of size 3\n",
    "        Standard deviation to be divided from image. Default is [0.229, 0.224, 0.225].\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, width, height, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "        self._width = width\n",
    "        self._height = height\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def __call__(self, src, label):\n",
    "        \"\"\"Apply transform to validation image/label.\"\"\"\n",
    "        # resize\n",
    "        h, w, _ = src.shape\n",
    "        \"\"\"\n",
    "        0: Nearest Neighbors Interpolation.\n",
    "        1: Bilinear interpolation.\n",
    "        2: Area-based (resampling using pixel area relation). It may be a\n",
    "        preferred method for image decimation, as it gives moire-free\n",
    "        results. But when the image is zoomed, it is similar to the Nearest\n",
    "        Neighbors method. (used by default).\n",
    "        3: Bicubic interpolation over 4x4 pixel neighborhood.\n",
    "        4: Lanczos interpolation over 8x8 pixel neighborhood.\n",
    "        9: Cubic for enlarge, area for shrink, bilinear for others\n",
    "        10: Random select from interpolation method metioned above.\n",
    "        \"\"\"\n",
    "        img = mx.image.imresize(src, self._width, self._height, interp=2)\n",
    "        bbox = self.bbox_resize(bbox=label, in_size=(w, h), out_size=(self._width, self._height))\n",
    "\n",
    "        img = mx.nd.image.to_tensor(img)\n",
    "        img = mx.nd.image.normalize(img, mean=self._mean, std=self._std)\n",
    "        return img, bbox.astype(img.dtype)\n",
    "\n",
    "    def bbox_resize(self, bbox, in_size, out_size):\n",
    "        \"\"\"Resize bouding boxes according to image resize operation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bbox : numpy.ndarray\n",
    "            :math:`(x_{min}, y_{min}, x_{max}, y_{max})`,\n",
    "        in_size : tuple\n",
    "            Tuple of length 2: (width, height) for input.\n",
    "        out_size : tuple\n",
    "            Tuple of length 2: (width, height) for output.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Resized bounding boxes with original shape.\n",
    "        \"\"\"\n",
    "\n",
    "        bbox = nd.array(bbox.copy())\n",
    "        x_scale = out_size[0] / in_size[0]\n",
    "        y_scale = out_size[1] / in_size[1]\n",
    "        bbox[:, 1] = y_scale * bbox[:, 1]\n",
    "        bbox[:, 3] = y_scale * bbox[:, 3]\n",
    "        bbox[:, 0] = x_scale * bbox[:, 0]\n",
    "        bbox[:, 2] = x_scale * bbox[:, 2]\n",
    "        return bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_clip_xyxy(xyxy, width, height):\n",
    "    \"\"\"Clip bounding box with format (xmin, ymin, xmax, ymax) to specified boundary.\n",
    "\n",
    "    All bounding boxes will be clipped to the new region `(0, 0, width, height)`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyxy : list, tuple or numpy.ndarray\n",
    "        The bbox in format (xmin, ymin, xmax, ymax).\n",
    "        If numpy.ndarray is provided, we expect multiple bounding boxes with\n",
    "        shape `(N, 4)`.\n",
    "    width : int or float\n",
    "        Boundary width.\n",
    "    height : int or float\n",
    "        Boundary height.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    type\n",
    "        Description of returned object.\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(xyxy, (tuple, list)):\n",
    "        if not len(xyxy) == 4:\n",
    "            raise IndexError(\n",
    "                \"Bounding boxes must have 4 elements, given {}\".format(len(xyxy)))\n",
    "        x1 = np.minimum(width - 1, np.maximum(0, xyxy[0]))\n",
    "        y1 = np.minimum(height - 1, np.maximum(0, xyxy[1]))\n",
    "        x2 = np.minimum(width - 1, np.maximum(0, xyxy[2]))\n",
    "        y2 = np.minimum(height - 1, np.maximum(0, xyxy[3]))\n",
    "        return (x1, y1, x2, y2)\n",
    "    elif isinstance(xyxy, np.ndarray):\n",
    "        if not xyxy.size % 4 == 0:\n",
    "            raise IndexError(\n",
    "                \"Bounding boxes must have n * 4 elements, given {}\".format(xyxy.shape))\n",
    "        x1 = np.minimum(width - 1, np.maximum(0, xyxy[:, 0]))\n",
    "        y1 = np.minimum(height - 1, np.maximum(0, xyxy[:, 1]))\n",
    "        x2 = np.minimum(width - 1, np.maximum(0, xyxy[:, 2]))\n",
    "        y2 = np.minimum(height - 1, np.maximum(0, xyxy[:, 3]))\n",
    "        return np.hstack((x1, y1, x2, y2))\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            'Expect input xywh a list, tuple or numpy.ndarray, given {}'.format(type(xyxy)))\n",
    "\n",
    "def bbox_xywh_to_xyxy(xywh):\n",
    "    \"\"\"Convert bounding boxes from format (x, y, w, h) to (xmin, ymin, xmax, ymax)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xywh : list, tuple or numpy.ndarray\n",
    "        The bbox in format (x, y, w, h).\n",
    "        If numpy.ndarray is provided, we expect multiple bounding boxes with\n",
    "        shape `(N, 4)`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple or numpy.ndarray\n",
    "        The converted bboxes in format (xmin, ymin, xmax, ymax).\n",
    "        If input is numpy.ndarray, return is numpy.ndarray correspondingly.\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(xywh, (tuple, list)):\n",
    "        if not len(xywh) == 4:\n",
    "            raise IndexError(\n",
    "                \"Bounding boxes must have 4 elements, given {}\".format(len(xywh)))\n",
    "        w, h = np.maximum(xywh[2] - 1, 0), np.maximum(xywh[3] - 1, 0)\n",
    "        return (xywh[0], xywh[1], xywh[0] + w, xywh[1] + h)\n",
    "    elif isinstance(xywh, np.ndarray):\n",
    "        if not xywh.size % 4 == 0:\n",
    "            raise IndexError(\n",
    "                \"Bounding boxes must have n * 4 elements, given {}\".format(xywh.shape))\n",
    "        xyxy = np.hstack((xywh[:, :2], xywh[:, :2] + np.maximum(0, xywh[:, 2:4] - 1)))\n",
    "        return xyxy\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            'Expect input xywh a list, tuple or numpy.ndarray, given {}'.format(type(xywh)))\n",
    "\n",
    "\n",
    "class LoadCOCO(object):\n",
    "    \"\"\"解析 ann 文件，保存所有 label 信息，并在 get_item 函数中读取图片，返回图片 img, label\n",
    "    img 是 ndarray\n",
    "    label 格式 ([xmin, ymin, xmax, ymax, contiguous_cid])\n",
    "    MS COCO detection dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : str, default '~/mxnet/datasets/coco'\n",
    "        Path to folder storing the dataset.\n",
    "    splits : list of str, default ['instances_val2017']\n",
    "        Json annotations name.\n",
    "        Candidates can be: instances_val2017, instances_train2017.\n",
    "    transform : callable, defaut None\n",
    "        A function that takes data and label and transforms them. Refer to\n",
    "        :doc:`./transforms` for examples.\n",
    "\n",
    "        A transform function for object detection should take label into consideration,\n",
    "        because any geometric modification will require label to be modified.\n",
    "    min_object_area : float\n",
    "        Minimum accepted ground-truth area\n",
    "    skip_empty : bool, default is True\n",
    "        Whether skip images with no valid object. This should be `True` in training, otherwise\n",
    "        it will cause undefined behavior.\n",
    "    use_crowd : bool, default is True\n",
    "        Whether use boxes labeled as crowd instance.\n",
    "\n",
    "    \"\"\"\n",
    "    CLASSES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train',\n",
    "               'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "               'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "               'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "               'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "               'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
    "               'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "               'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "               'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n",
    "               'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "               'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "               'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "    def __init__(self, root=os.path.join('~', 'datasets', 'coco'),\n",
    "                 splits=('instances_val2017',), transform=None, min_object_area=0,\n",
    "                 skip_empty=True, use_crowd=True):\n",
    "        self._root = os.path.expanduser(root)\n",
    "        self._transform = transform\n",
    "        self._min_object_area = min_object_area\n",
    "        self._skip_empty = skip_empty\n",
    "        self._use_crowd = use_crowd\n",
    "        self.num_class = len(type(self).CLASSES)\n",
    "        if isinstance(splits, mx.base.string_types):\n",
    "            splits = [splits]\n",
    "        self._splits = splits\n",
    "        # to avoid trouble, we always use contiguous IDs except dealing with cocoapi\n",
    "        self.index_map = dict(zip(type(self).CLASSES, range(self.num_class)))\n",
    "        self.json_id_to_contiguous = None\n",
    "        self.contiguous_id_to_json = None\n",
    "        self._coco = []\n",
    "        self._items, self._labels = self._load_jsons()\n",
    "\n",
    "    def __str__(self):\n",
    "        detail = ','.join([str(s) for s in self._splits])\n",
    "        return self.__class__.__name__ + '(' + detail + ')'\n",
    "\n",
    "    @property\n",
    "    def coco(self):\n",
    "        \"\"\"Return pycocotools object for evaluation purposes.\"\"\"\n",
    "        if not self._coco:\n",
    "            raise ValueError(\"No coco objects found, dataset not initialized.\")\n",
    "        elif len(self._coco) > 1:\n",
    "            raise NotImplementedError(\n",
    "                \"Currently we don't support evaluating {} JSON files\".format(len(self._coco)))\n",
    "        return self._coco[0]\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        \"\"\"Category names.\"\"\"\n",
    "        return type(self).CLASSES\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self._items[idx]\n",
    "        label = self._labels[idx]\n",
    "        img = mx.image.imread(img_path, 1)\n",
    "        if self._transform is not None:\n",
    "            return self._transform(img, label)\n",
    "        return img, np.array(label)\n",
    "\n",
    "    def _load_jsons(self):\n",
    "        \"\"\"Load all image paths and labels from JSON annotation files into buffer.\"\"\"\n",
    "        items = []\n",
    "        labels = []\n",
    "        # lazy import pycocotools\n",
    "        from cocoapi.PythonAPI.pycocotools.coco import COCO\n",
    "        for split in self._splits:\n",
    "            anno = os.path.join(self._root, 'annotations', split) + '.json'\n",
    "            _coco = COCO(anno)\n",
    "            self._coco.append(_coco)\n",
    "            classes = [c['name'] for c in _coco.loadCats(_coco.getCatIds())]\n",
    "            if not classes == self.classes:\n",
    "                raise ValueError(\"Incompatible category names with COCO: \")\n",
    "            assert classes == self.classes\n",
    "            json_id_to_contiguous = {\n",
    "                v: k for k, v in enumerate(_coco.getCatIds())}\n",
    "            if self.json_id_to_contiguous is None:\n",
    "                self.json_id_to_contiguous = json_id_to_contiguous\n",
    "                self.contiguous_id_to_json = {\n",
    "                    v: k for k, v in self.json_id_to_contiguous.items()}\n",
    "            else:\n",
    "                assert self.json_id_to_contiguous == json_id_to_contiguous\n",
    "\n",
    "            # iterate through the annotations\n",
    "            image_ids = sorted(_coco.getImgIds())\n",
    "            for entry in _coco.loadImgs(image_ids):\n",
    "                dirname, filename = entry['coco_url'].split('/')[-2:]\n",
    "                abs_path = os.path.join(self._root, dirname, filename)\n",
    "                if not os.path.exists(abs_path):\n",
    "                    raise IOError('Image: {} not exists.'.format(abs_path))\n",
    "                label = self._check_load_bbox(_coco, entry)\n",
    "                if not label:\n",
    "                    continue\n",
    "                items.append(abs_path)\n",
    "                labels.append(label)\n",
    "        return items, labels\n",
    "\n",
    "    def _check_load_bbox(self, coco, entry):\n",
    "        \"\"\"Check and load ground-truth labels\"\"\"\n",
    "        ann_ids = coco.getAnnIds(imgIds=entry['id'], iscrowd=None)\n",
    "        objs = coco.loadAnns(ann_ids)\n",
    "        # check valid bboxes\n",
    "        valid_objs = []\n",
    "        width = entry['width']\n",
    "        height = entry['height']\n",
    "        for obj in objs:\n",
    "            if obj['area'] < self._min_object_area:\n",
    "                continue\n",
    "            if obj.get('ignore', 0) == 1:\n",
    "                continue\n",
    "            if not self._use_crowd and obj.get('iscrowd', 0):\n",
    "                continue\n",
    "            # convert from (x, y, w, h) to (xmin, ymin, xmax, ymax) and clip bound\n",
    "            xmin, ymin, xmax, ymax = bbox_clip_xyxy(bbox_xywh_to_xyxy(obj['bbox']), width, height)\n",
    "            # require non-zero box area\n",
    "            if obj['area'] > 0 and xmax > xmin and ymax > ymin:\n",
    "                contiguous_cid = self.json_id_to_contiguous[obj['category_id']]\n",
    "                valid_objs.append([xmin, ymin, xmax, ymax, contiguous_cid])\n",
    "        if not valid_objs:\n",
    "            if not self._skip_empty:\n",
    "                # dummy invalid labels if no valid objects are found\n",
    "                valid_objs.append([-1, -1, -1, -1, -1])\n",
    "        return valid_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 内存太小，只能使用验证集进行 fine-tune\n",
    "#train_dataset = LoadCOCO(root='~/data/coco', splits=['instances_train2017'], transform=None)\n",
    "val_dataset = LoadCOCO(root='~/data/coco', splits=['instances_val2017'], transform=ValTransform(img_wight, img_height))\n",
    "#val_dataset = LoadCOCO(root='~/data/coco', splits=['instances_val2017'], transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "# behavior of batchify_fn: stack images, and pad labels\n",
    "# 如果将不同长度的数组堆叠，会直接异常报错\n",
    "batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "\n",
    "## 数据加载\n",
    "# from mxnet.gluon.data import DataLoader\n",
    "# 这个函数最主要实现的目的就是每次返回 batch_size 大小的样本 [ Loads data from a dataset and returns mini-batches of data. ]\n",
    "# 阅读 DataLoader 代码发现，这个函数就是先依据入参生成所有样本 batch_sampler (经过 shuffle 或者顺序读取)，\n",
    "# 然后生成一个迭代器，每次返回 batch_size 大小的样本，且会将这些样本进行函数 batchify_fn 处理 \n",
    "# 当然还可以使用多个线程同时读取，可以预先读取一定数量的样本等等\n",
    "# 可以自己去实现，但是感觉没有必要\n",
    "# 参数\n",
    "#    dataset : ndarray or numpy array. 应该是经过 transform 之后的数据\n",
    "#    batch_size : int\n",
    "#    shuffle : bool\n",
    "#    sampler : Sampler\n",
    "#    last_batch : {'keep', 'discard', 'rollover'}\n",
    "#    batch_sampler : Sampler\n",
    "#    batchify_fn : callable. 用户自定义组装样本的方法\n",
    "#    num_workers : int, default 0. 使用 num_workers 个线程来读取样本\n",
    "#    pin_memory : boolean, default False. 使用函数 mxnet.ndarray.ndarray.NDArray.as_in_context(context) 实现，加快从 CPU 到 GPU 的拷贝速度\n",
    "#    prefetch : int, default is `num_workers * 2`. 预处理样本的个数，会消耗较大的 shared_memory （应该是 GPU 的），当 num_workers > 0 时生效\n",
    "\n",
    "loader_train = DataLoader(val_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True, \n",
    "                          batchify_fn=batchify_fn,\n",
    "                          last_batch='roolover', \n",
    "                          num_workers=num_workers)\n",
    "\n",
    "#loader_val   = DataLoader(val_dataset,\n",
    "#                          batch_size=batch_size, \n",
    "#                          shuffle=False, \n",
    "#                          batchify_fn=batchify_fn,\n",
    "#                          last_batch='discard', \n",
    "#                          num_workers=num_workers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default configurations\n",
    "residual_block_num = [1, 2, 8, 8, 4] # 残差块的个数\n",
    "darknet_channels = [32, [32, 64, 128, 256, 512]] # 对应残差块 1x1 卷积输出 channel 个数，3x3 卷积输出 channel 个数翻倍\n",
    "class_num_imagenet = 1000 # for imagenet\n",
    "\n",
    "# 三个输出分别使用的检测通道数\n",
    "det_channels = [512, 256, 128]\n",
    "\n",
    "# 这里都进行了反序\n",
    "strides = [32, 16, 8]\n",
    "anchors = [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]    \n",
    "\n",
    "# coco 80 个类\n",
    "classes_name = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', \n",
    "                'train', 'truck', 'boat', 'traffic light', 'fire hydrant', \n",
    "                'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', \n",
    "                'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', \n",
    "                'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "                'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', \n",
    "                'baseball glove', 'skateboard', 'surfboard', 'tennis racket', \n",
    "                'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', \n",
    "                'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', \n",
    "                'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "                'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', \n",
    "                'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', \n",
    "                'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', \n",
    "                'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "\n",
    "\n",
    "def cbl_gen(channels, kernel_size, strides, padding):\n",
    "    '''conv-BN-LeakyReLU cell'''\n",
    "    cbl_unit = nn.HybridSequential()\n",
    "    # 所有卷积后面都有 BN ，所以 bias 始终为 False\n",
    "    cbl_unit.add(\n",
    "        nn.Conv2D(channels, kernel_size=kernel_size, strides=strides, padding=padding, groups=1, use_bias=False),\n",
    "        nn.BatchNorm(),\n",
    "        nn.LeakyReLU(0.1)\n",
    "    )\n",
    "    \n",
    "    return cbl_unit\n",
    "\n",
    "# 残差网络需要重新定义前向传播的方式，必须自己定义网络层类\n",
    "class DarknetBasicBlockV3(gluon.HybridBlock):\n",
    "    '''darknetV3 basic block\n",
    "    net.hybridize() 可以为继承 HybridBlock 类的层优化计算性能\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, channels, **kwargs):        \n",
    "        super(DarknetBasicBlockV3, self).__init__(**kwargs)        \n",
    "        self.body = nn.HybridSequential()\n",
    "        self.body.add(\n",
    "            # 1x1 conv; 看 darknet 中 yolov3.cfg 文件中 1x1 卷积的 padding 也是 1 ？？？ gluoncv 中并没有\n",
    "            cbl_gen(channels, (1,1), (1,1), (0,0)),\n",
    "            # 3x3 conv\n",
    "            cbl_gen(channels*2, (3,3), (1,1), (1,1))\n",
    "        )\n",
    "    # 需要在 hybrid_forward 函数中添加额外的输入F。由于 MXNet 既有基于命令式编程的 NDArray 类，\n",
    "    # 又有基于符号式编程的 Symbol 类。由于这两个类的函数基本一致，MXNet会根据输入来决定 F 使用 NDArray 或 Symbol。    \n",
    "    def hybrid_forward(self, F, x):\n",
    "        return x + self.body(x)\n",
    "\n",
    "        \n",
    "class Darknet53(gluon.HybridBlock):\n",
    "    '''darknet53'''\n",
    "    \n",
    "    def __init__(self, residual_block_num, channels, class_num=1000, **kwargs):\n",
    "        super(Darknet53, self).__init__(**kwargs)\n",
    "        self.features = nn.HybridSequential()\n",
    "        \n",
    "        # 网络最开始有一个卷积操作\n",
    "        self.features.add(cbl_gen(channels[0], (3,3), (1,1), (1,1)))\n",
    "        \n",
    "        # 重复的残差块\n",
    "        for residual_block, channel in zip(residual_block_num, channels[1]):\n",
    "            # 使用步长为 2 的卷积实现下采样，在每一个残差块的开始都有一个下采样层\n",
    "            self.features.add(cbl_gen(channel*2, (3,3), (2,2), (1,1)))\n",
    "            # 一个残差块\n",
    "            for _ in range(residual_block):\n",
    "                self.features.add(DarknetBasicBlockV3(channel))\n",
    "        \n",
    "        # global average pooling\n",
    "        self.pooling = nn.GlobalAvgPool2D()\n",
    "        # 全连接的输出层\n",
    "        self.output = nn.Dense(class_num)\n",
    "        \n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pooling(x)\n",
    "        return self.output(x)\n",
    "\n",
    "    \n",
    "class Concates(gluon.HybridBlock):\n",
    "    \"\"\"不同 stage 的 feature maps 串接的时候，先经过了一个 1x1 卷积和一个上采样\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, **kwargs):\n",
    "        super(Concates, self).__init__(*kwargs)\n",
    "        self.concate = nn.HybridSequential(prefix='')\n",
    "        self.concate.add(cbl_gen(channels, (1,1), (1,1), (0,0)))\n",
    "        \n",
    "    def upsample_rept(self, x, stride):\n",
    "        '''\n",
    "        不同的检测层输入堆叠的时候需要上采样，上采样的方式也很简单，\n",
    "        只是将 feature maps 沿着水平和垂直方向 repeat 指定的倍数。\n",
    "        '''\n",
    "        assert type(x) == mx.ndarray.ndarray.NDArray or type(x) == np.ndarray\n",
    "        return x.repeat(axis=-1, repeats=stride).repeat(axis=-2, repeats=stride)    \n",
    "    \n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.concate(x)\n",
    "        x = self.upsample_rept(x, 2)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Detection(gluon.HybridBlock):\n",
    "    '''\n",
    "    检测网络，三个检测网络的结构相同，只是 filter 个数不同,\n",
    "    完全可以使用一个 for 循环实现，\n",
    "    但是需要在倒数第二层引出分支，和前面层的特征合并后，用于前面的检测网络，所以只能分开写\n",
    "\n",
    "    越靠近输入层， feature maps 越大，所以检测网络使用的 channel 相应的较少，防止较大运算量\n",
    "    '''\n",
    "    def __init__(self, channels, classes_num=80, anchors_num=3, **kwargs):\n",
    "        super(Detection, self).__init__(**kwargs)\n",
    "        self.channels=channels\n",
    "        self.anchors_num=anchors_num\n",
    "        self.pred_num=1+4+classes_num\n",
    "        self.body=nn.HybridSequential(prefix='')\n",
    "        self.tip=nn.HybridSequential(prefix='')\n",
    "\n",
    "        for i in range(2):\n",
    "            self.body.add(cbl_gen(channels, (1,1), (1,1), (0,0)))\n",
    "            self.body.add(cbl_gen(channels*2, (3,3), (1,1), (1,1)))\n",
    "            \n",
    "        self.body.add(cbl_gen(channels, (1,1), (1,1), (0,0)))        \n",
    "        self.tip.add(cbl_gen(channels*2, (3,3), (1,1), (1,1)))        \n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.body(x)\n",
    "        return self.tip(x)\n",
    "\n",
    "\n",
    "class Output(gluon.HybridBlock):\n",
    "    \"\"\"YOLOv3 输出\n",
    "    \"\"\"\n",
    "    def __init__(self, anchors, stride, classes_num=80, **kwargs):\n",
    "        super(Output, self).__init__(**kwargs)\n",
    "        self.stride = stride\n",
    "        self.anchors_num = len(anchors) // 2\n",
    "        self.classes_num = classes_num\n",
    "        self.pred_num = 1+4+classes_num\n",
    "        anchors = nd.array(anchors).astype('float32')\n",
    "        self.anchors = anchors.reshape(1, 1, -1, 2)\n",
    "\n",
    "        self.output = nn.HybridSequential(prefix='')\n",
    "        # 这里是线性激活函数，默认 nn.Conv2D 的 activation=None，两者等效\n",
    "        # 输出 channel 的个数 (4+1+classes)*anchors\n",
    "        self.output.add(nn.Conv2D(self.pred_num*self.anchors_num, (1,1), (1,1), (0,0), groups=1, use_bias=True))        \n",
    "\n",
    "        # offsets will be added to predictions\n",
    "        grid_x = np.arange(52)\n",
    "        grid_y = np.arange(52)\n",
    "        grid_x, grid_y = np.meshgrid(grid_x, grid_y)\n",
    "        # stack to (n, n, 2)\n",
    "        offsets = np.concatenate((grid_x[:, :, np.newaxis], grid_y[:, :, np.newaxis]), axis=-1)\n",
    "        # expand dims to (1, 1, n, n, 2) so it's easier for broadcasting\n",
    "        offsets = np.expand_dims(np.expand_dims(offsets, axis=0), axis=0)\n",
    "        self.offsets = nd.array(offsets)#self.params.get_constant('offset_%d'%(index), offsets)\n",
    "        \n",
    "    def hybrid_forward(self, F, x):\n",
    "        pred = self.output(x)\n",
    "\n",
    "        # prediction flat to (batch, pred per pixel, height * width)\n",
    "        pred = pred.reshape((0, self.anchors_num * self.pred_num, -1))\n",
    "        # transpose to (batch, height * width, num_anchor, num_pred)\n",
    "        pred = pred.transpose(axes=(0, 2, 1)).reshape((0, -1, self.anchors_num, self.pred_num))\n",
    "        # components\n",
    "        raw_box_centers = pred.slice_axis(axis=-1, begin=0, end=2)\n",
    "        raw_box_scales = pred.slice_axis(axis=-1, begin=2, end=4)\n",
    "        objness = pred.slice_axis(axis=-1, begin=4, end=5)\n",
    "        class_pred = pred.slice_axis(axis=-1, begin=5, end=None)\n",
    "\n",
    "        # valid offsets, (1, 1, height, width, 2)\n",
    "        offsets = nd.slice_like(self.offsets, x * 0, axes=(2, 3))\n",
    "        # reshape to (1, height*width, 1, 2)\n",
    "        offsets = offsets.reshape((1, -1, 1, 2))\n",
    "\n",
    "        box_centers = nd.broadcast_add(nd.sigmoid(raw_box_centers), offsets) * self.stride\n",
    "        box_scales = nd.broadcast_mul(nd.exp(raw_box_scales), self.anchors)\n",
    "        confidence = nd.sigmoid(objness)\n",
    "        class_score = nd.broadcast_mul(nd.sigmoid(class_pred), confidence)\n",
    "        wh = box_scales / 2.0\n",
    "        # `corner`: [xmin, ymin, xmax, ymax]\n",
    "        # `center`: [x, y, width, height]\n",
    "        # center to corner\n",
    "        bbox = nd.concat(box_centers - wh, box_centers + wh, dim=-1)\n",
    "\n",
    "        if autograd.is_training():\n",
    "            # during training, we don't need to convert whole bunch of info to detection results\n",
    "            return (bbox.reshape((0, -1, 4)), raw_box_centers, raw_box_scales,\n",
    "                    objness, class_pred, self.anchors, offsets)\n",
    "\n",
    "        # prediction per class\n",
    "        bboxes = nd.tile(bbox, reps=(self.classes_num, 1, 1, 1, 1))\n",
    "        scores = nd.transpose(class_score, axes=(3, 0, 1, 2)).expand_dims(axis=-1)\n",
    "        ids = nd.broadcast_add(scores * 0, F.arange(0, self.classes_num).reshape((0, 1, 1, 1, 1)))\n",
    "        detections = nd.concat(ids, scores, bboxes, dim=-1)\n",
    "        # reshape to (B, xx, 6)\n",
    "        detections = nd.reshape(detections.transpose(axes=(1, 0, 2, 3, 4)), (0, -1, 6))\n",
    "        return detections\n",
    "\n",
    "\n",
    "class YOLOv3(gluon.HybridBlock):\n",
    "    \"\"\"生成 YOLOv3 网络，只适用于 Darknet53 ，\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(YOLOv3, self).__init__(**kwargs)\n",
    "\n",
    "        # 基本网络框架\n",
    "        darknet53 = Darknet53(residual_block_num, darknet_channels)\n",
    "        # residual_block_num = [1, 2, 8, 8, 4] , 每一个残差块的开始都有一个下采样层\n",
    "        feature1_layer = 1 + (1+1) + (1+2) + (1+8)\n",
    "        feature2_layer = feature1_layer + (1+8)\n",
    "        feature3_layer = feature2_layer + (1+4) # 可以直接到末尾，\n",
    "\n",
    "        self.features = nn.HybridSequential(prefix='')\n",
    "        self.features.add(darknet53.features[:feature1_layer])\n",
    "        self.features.add(darknet53.features[feature1_layer:feature2_layer])\n",
    "        self.features.add(darknet53.features[feature2_layer:feature3_layer])\n",
    "\n",
    "        # 从基本网络框架引出的检测网络层，包含输出\n",
    "        self.detection_net = nn.HybridSequential(prefix='')\n",
    "        for det_channel in det_channels:\n",
    "            self.detection_net.add(Detection(det_channel))\n",
    "\n",
    "        # 串接不同 stage \n",
    "        self.concates = nn.HybridSequential(prefix='')\n",
    "        for det_channel in det_channels[1:]:\n",
    "            self.concates.add(Concates(det_channel))\n",
    " \n",
    "        # 输出\n",
    "        self.output = nn.HybridSequential(prefix='')\n",
    "        for anchor, stride in zip(anchors, strides):\n",
    "            self.output.add(Output(anchor, stride))\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        # 先计算出所有 stage 的 features\n",
    "        featuremaps = []\n",
    "        for net in self.features:\n",
    "            x = net(x)\n",
    "            featuremaps.append(x)\n",
    "\n",
    "        # 反序\n",
    "        featuremaps = featuremaps[::-1]\n",
    "\n",
    "        output = []\n",
    "        det = nd.array([])\n",
    "        for i in range(len(featuremaps)):\n",
    "            if i == 0:\n",
    "                det = featuremaps[i]\n",
    "            else:\n",
    "                det = self.concates[i-1](det)\n",
    "                det = nd.concat(det, featuremaps[i], dim=1)\n",
    "\n",
    "            det = self.detection_net[i].body(det)   \n",
    "            out = self.detection_net[i].tip(det)\n",
    "            out = self.output[i](out)\n",
    "            output.append(out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载参数\n",
    "net = YOLOv3()\n",
    "\n",
    "def load_yolov3_param(net):\n",
    "    net.features.load_parameters('features.params')\n",
    "\n",
    "    # 由于和 gluoncv 的网络结构不同（自己的网络 tip 外面有两层 HybridSequential ），只能分开加载\n",
    "    for i in range(3):\n",
    "        name = \"body_%d.params\" % (i)\n",
    "        net.detection_net[i].body.load_parameters(name)\n",
    "        name = \"tip_%d.params\" % (i)\n",
    "        net.detection_net[i].tip[0].load_parameters(name)\n",
    "\n",
    "    for i in range(2):\n",
    "        name = \"concate_%d.params\" % (i)\n",
    "        net.concates[i].concate[0].load_parameters(name)\n",
    "\n",
    "    for i in range(3):\n",
    "        name = \"outputs_%d.params\" % (i)\n",
    "        net.output[i].output[0].load_parameters(name)\n",
    "    \n",
    "    return net\n",
    "\n",
    "net = load_yolov3_param(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 冻结原有层的权重\n",
    "#resnet18_cifar10[0].collect_params().setattr('grad_req', 'null')\n",
    "## 初始化自定义层的权重\n",
    "#resnet18_cifar10[1].initialize(init=mx.init.Xavier(), ctx=ctx)\n",
    "\n",
    "# 通过正则表达式选择层\n",
    "#net.collect_params('.*dense')\n",
    "# 通过 lr_mult 设置学习速率\n",
    "#net.collect_params('.*dense').setattr('lr_mult',0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gluon.Trainer 使用指定的最优化方法来更新参数\n",
    "trainer = gluon.Trainer(yolov3_model.collect_params(), optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 网络训练\n",
    "def train_net(net, data_train, data_val, trainer, epochs):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        #metric.reset()\n",
    "        train_loss = 0\n",
    "        update_learn_rate(trainer, epoch, lr_decay_epochs, lr_decay)\n",
    "        tic = time.time()\n",
    "        \n",
    "        # dataset 是可迭代对象\n",
    "        for i, batch in enumerate(loader_train):\n",
    "            # 将数据切片分别加载到不同的设备上 ； 主要操作就是\n",
    "            # data = nd.array(data, ctx=ctx[0]).as_in_context(ctx[0])\n",
    "            # 终于发现自己的愚蠢，不可以将不同维度的数据一起加载\n",
    "            # 合并两个不同大小的 array 有问题，将导致 ZMQbg/1 占用 CPU 100% \n",
    "            # 假如有 n 个 GPU ，前面的 DataLoader 中 batch_size 是不是应该是 batch*n ? TODO\n",
    "            data_train = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "            label_train = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
    "            # label 为 (xmin,ymin,xmax,ymax,cid)\n",
    "            \n",
    "            # 自动求导: record() 函数使得 mxnet 记录并计算梯度，需要训练的参数都需要计算梯度\n",
    "            with autograd.record():\n",
    "                output = [net(X) for X in data_train]\n",
    "                loss = [loss_fn(yhat, y) for yhat, y in zip(output, label_train)]\n",
    "\n",
    "            # loss 是 list ，当有多个 loss 的时候，所有的 loss 都需要反向传播\n",
    "            # l 是 mxnet.ndarray.ndarray.NDArray 格式的数据，本身就有 backward() 函数\n",
    "            # 调用 backward() 函数用于计算梯度\n",
    "            for l in loss:\n",
    "                l.backward()\n",
    "            \n",
    "            # 更新参数， 通过调用 allreduce_grads() 和 update() 来实现参数的更新\n",
    "            # 必须在 autograd.backward() 之后，以及 record() 之外调用\n",
    "            # allreduce_grads() 必须在 trainer.update() 之前调用\n",
    "            # 这里更新的时候是怎样用到上面计算的 loss 的？\n",
    "            # trainer 已经中指定了需要训练的参数，应该是可以在某个位置找到这些参数的梯度，从而使用指定的最优化方法来更新参数\n",
    "            trainer.step(batch_size)\n",
    "                        \n",
    "            for l in loss:\n",
    "                train_loss += l.sum().asscalar() / batch_size\n",
    "            \n",
    "            # 每个 batch 更新一下训练的准确率\n",
    "            metric.update(label_train, output)\n",
    "            \n",
    "        _, acc = metric.get()\n",
    "        _, val_acc = metric_val(net, dataset_val, ctx=ctx)\n",
    "        \n",
    "        # 这里记录的是错误率\n",
    "        train_history.update([1-acc, 1-val_acc])\n",
    "        \n",
    "        toc = time.time()\n",
    "        \n",
    "        print('[epoch %d] train_loss=%f, acc=%f, val_acc=%f, lr=%.9f, time: %fs' % \n",
    "              (epoch, train_loss, acc, val_acc, trainer.learning_rate, toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gluoncv 提供的 transform 函数\n",
    "#from gluoncv.data.transforms import presets\n",
    "#presets.yolo.YOLO3DefaultTrainTransform\n",
    "#presets.rcnn.FasterRCNNDefaultTrainTransform\n",
    "\n",
    "## 数据预处理\n",
    "## 牢记 mxnet 使用 BCHW 形式\n",
    "\n",
    "# Dataset 类提供了两个转换函数： transform_first 和 transform ；\n",
    "# transform_first 只变换 data ； transform 同时变换样本和标签（一个样本的所有数据）\n",
    "\n",
    "# imgnet 数据集\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# 写两个函数，一个是 train_transform 一个 test_transform\n",
    "def train_transform(img, label, mean, std):\n",
    "    \"\"\"\n",
    "    YOLOv3 默认的数据预处理，图像和标签都需要处理\n",
    "    1. random color jittering\n",
    "    1. random expansion with prob 0.5\n",
    "    1. random cropping\n",
    "    1. resize with random interpolation\n",
    "    1. random horizontal flip\n",
    "    1. to tensor\n",
    "    1. nomalize\n",
    "    \"\"\"\n",
    "    \n",
    "    # random color jittering\n",
    "    mx.nd.image.random_color_jitter()\n",
    "    \n",
    "    # random expansion with prob 0.5\n",
    "    \n",
    "    # random cropping\n",
    "    mx.image.fixed_crop()\n",
    "    mx.image.random_crop()\n",
    "    \n",
    "    # resize with random interpolation\n",
    "    mx.image.imresize() # interp 利用入参进行了设置 (img, width, height, interp=interp)\n",
    "    \n",
    "    # random horizontal flip\n",
    "    mx.nd.image.random_flip_left_right()\n",
    "    \n",
    "    # to tensor WHC -> CHW\n",
    "    img = mx.nd.image.to_tensor(img)\n",
    "    \n",
    "    # nomalize\n",
    "    img = mx.nd.image.normalize(img, mean, std)\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def test_transform(img, lable, mean, std):\n",
    "    \n",
    "    # resize with random interpolation\n",
    "    mx.image.imresize() # interp 利用入参进行了设置 (img, width, height, interp=interp)\n",
    "    \n",
    "    # to tensor WHC -> CHW\n",
    "    img = mx.nd.image.to_tensor(img)\n",
    "    \n",
    "    # nomalize\n",
    "    img = mx.nd.image.normalize(img, mean, std)\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "\n",
    "# gluoncv 代码实现\n",
    "def transform(src, label, width, height, mean, std):\n",
    "    \"\"\"Apply transform to training image/label.\"\"\"\n",
    "    # random color jittering\n",
    "    img = experimental.image.random_color_distort(src)\n",
    "\n",
    "    # random expansion with prob 0.5\n",
    "    if np.random.uniform(0, 1) > 0.5:\n",
    "        img, expand = timage.random_expand(img, fill=[m * 255 for m in mean])\n",
    "        bbox = tbbox.translate(label, x_offset=expand[0], y_offset=expand[1])\n",
    "    else:\n",
    "        img, bbox = img, label\n",
    "\n",
    "    # random cropping\n",
    "    h, w, _ = img.shape\n",
    "    bbox, crop = experimental.bbox.random_crop_with_constraints(bbox, (w, h))\n",
    "    x0, y0, w, h = crop\n",
    "    img = mx.image.fixed_crop(img, x0, y0, w, h)\n",
    "\n",
    "    # resize with random interpolation\n",
    "    h, w, _ = img.shape\n",
    "    interp = np.random.randint(0, 5)\n",
    "    img = timage.imresize(img, width, height, interp=interp)\n",
    "    bbox = tbbox.resize(bbox, (w, h), (width, height))\n",
    "\n",
    "    # random horizontal flip\n",
    "    h, w, _ = img.shape\n",
    "    img, flips = timage.random_flip(img, px=0.5)\n",
    "    bbox = tbbox.flip(bbox, (w, h), flip_x=flips[0])\n",
    "\n",
    "    # to tensor\n",
    "    img = mx.nd.image.to_tensor(img)\n",
    "    img = mx.nd.image.normalize(img, mean=mean, std=std)\n",
    "\n",
    "    return img, bbox.astype(img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 性能度量函数\n",
    "def metric_val(net, dataset_val, metric=None, ctx=mx.cpu(0)):\n",
    "    \n",
    "    if metric is None:\n",
    "        metric = mx.metric.Accuracy()\n",
    "        \n",
    "    for _, batch in enumerate(dataset_val):\n",
    "        # 将数据切片分别加载到不同的设备上\n",
    "        data_val = gluon.utils.split_and_load(batch[0], ctx, batch_axis=0)\n",
    "        label_val = gluon.utils.split_and_load(batch[1], ctx, batch_axis=0)\n",
    "        \n",
    "        yhat = [net(x) for x in data_val]\n",
    "        \n",
    "        # 第一个参数是 label ， 第二个参数是 output\n",
    "        metric.update(label_val, yhat)    \n",
    "  \n",
    "    return metric.get()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
