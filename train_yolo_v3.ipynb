{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Train YOLOv3 on PASCAL VOC\n",
    "================================\n",
    "\n",
    "This tutorial goes through the basic steps of training a YOLOv3 object detection model\n",
    "provided by GluonCV.\n",
    "\n",
    "Specifically, we show how to build a state-of-the-art YOLOv3 model by stacking GluonCV components.\n",
    "\n",
    "\n",
    ".. hint::\n",
    "\n",
    "    You can skip the rest of this tutorial and start training your YOLOv3 model\n",
    "    right away by downloading this script:\n",
    "\n",
    "    :download:`Download train_yolo3.py<../../../scripts/detection/yolo/train_yolo3.py>`\n",
    "    Random shape training requires more GPU memory but generates better results. You can turn it off by setting `--no-random-shape`.\n",
    "\n",
    "    Example usage:\n",
    "\n",
    "    Train a default darknet53 model with Pascal VOC on GPU 0:\n",
    "\n",
    "    .. code-block:: bash\n",
    "\n",
    "        python train_yolo3.py --gpus 0\n",
    "\n",
    "    Train a darknet53 model on GPU 0,1,2,3 with synchronize BatchNorm:\n",
    "\n",
    "    .. code-block:: bash\n",
    "\n",
    "        python train_yolo3.py --gpus 0,1,2,3 --network darknet53 --syncbn\n",
    "\n",
    "    Check the supported arguments:\n",
    "\n",
    "    .. code-block:: bash\n",
    "\n",
    "        python train_yolo3.py --help\n",
    "\n",
    "\n",
    ".. hint::\n",
    "\n",
    "    Since lots of contents in this tutorial is very similar to :doc:`./train_ssd_voc`, you can skip any part\n",
    "    if you feel comfortable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset\n",
    "-------\n",
    "\n",
    "Please first go through this `sphx_glr_build_examples_datasets_pascal_voc.py` tutorial to setup Pascal\n",
    "VOC dataset on your disk.\n",
    "Then, we are ready to load training and validation images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 5011\n",
      "Validation images: 4952\n"
     ]
    }
   ],
   "source": [
    "import gluoncv as gcv\n",
    "from gluoncv.data import VOCDetection\n",
    "# typically we use 2007+2012 trainval splits for training data\n",
    "train_dataset = VOCDetection(root='/home/kyle/data/VOC/VOCdevkit/', splits=[(2007, 'trainval')])#, (2012, 'trainval')])\n",
    "# and use 2007 test as validation data\n",
    "val_dataset = VOCDetection(root='/home/kyle/data/VOC/VOCdevkit/', splits=[(2007, 'test')])\n",
    "\n",
    "print('Training images:', len(train_dataset))\n",
    "print('Validation images:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dataset 是 VOCDetection 类的一个实例，提供 get_item 的方法获取对应索引的图片和标签；\n",
    "\n",
    "VOCDetection label 格式 (xmin, ymin, xmax, ymax, cls_id, difficlut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data transform\n",
    "--------------\n",
    "We can read an image-label pair from the training dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: (500, 334, 3)\n",
      "bboxes: (6, 4) class ids: (6, 1)\n"
     ]
    }
   ],
   "source": [
    "train_image, train_label = train_dataset[60]\n",
    "bboxes = train_label[:, :4]\n",
    "cids = train_label[:, 4:5]\n",
    "print('image:', train_image.shape)\n",
    "print('bboxes:', bboxes.shape, 'class ids:', cids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label: 6\n",
      "[[ 69. 201. 254. 499.   1.   0.]\n",
      " [250. 241. 333. 499.   1.   1.]\n",
      " [  0. 143.  66. 435.   1.   1.]\n",
      " [  0.   0.  65. 362.  14.   1.]\n",
      " [ 73.   0. 271. 461.  14.   0.]\n",
      " [251.  18. 333. 486.  14.   0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"train_label: %d\" % len(train_label))\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((train_dataset[60][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the image, together with the bounding box labels:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from gluoncv.utils import viz\n",
    "\n",
    "ax = viz.plot_bbox(train_image.asnumpy(), bboxes, labels=cids, class_names=train_dataset.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation images are quite similar to training because they were\n",
    "basically split randomly to different sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image, val_label = val_dataset[2112]\n",
    "bboxes = val_label[:, :4]\n",
    "cids = val_label[:, 4:5]\n",
    "ax = viz.plot_bbox(val_image.asnumpy(), bboxes, labels=cids, class_names=train_dataset.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For YOLOv3 networks, we apply similar transforms to SSD example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.transforms import presets\n",
    "from gluoncv import utils\n",
    "from mxnet import nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 416, 416  # resize image to 416x416 after all data augmentation\n",
    "train_transform = presets.yolo.YOLO3DefaultTrainTransform(width, height)\n",
    "val_transform = presets.yolo.YOLO3DefaultValTransform(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.random.seed(123)  # fix seed in this tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply transforms to train image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor shape: (3, 416, 416)\n"
     ]
    }
   ],
   "source": [
    "train_image2, train_label2 = train_transform(train_image, train_label)\n",
    "print('tensor shape:', train_image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images in tensor are distorted because they no longer sit in (0, 255) range.\n",
    "Let's convert them back so we can see them clearly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image2 = train_image2.transpose((1, 2, 0)) * nd.array((0.229, 0.224, 0.225)) + nd.array((0.485, 0.456, 0.406))\n",
    "train_image2 = (train_image2 * 255).clip(0, 255)\n",
    "ax = viz.plot_bbox(train_image2.asnumpy(), train_label2[:, :4],\n",
    "                   labels=train_label2[:, 4:5],\n",
    "                   class_names=train_dataset.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms used in training include random color distortion, random expand/crop, random flipping,\n",
    "resizing and fixed color normalization.\n",
    "In comparison, validation only involves resizing and color normalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader\n",
    "-----------\n",
    "We will iterate through the entire dataset many times during training.\n",
    "Keep in mind that raw images have to be transformed to tensors\n",
    "(mxnet uses BCHW format) before they are fed into neural networks.\n",
    "\n",
    "A handy DataLoader would be very convenient for us to apply different transforms and aggregate data into mini-batches.\n",
    "\n",
    "Because the number of objects varys a lot across images, we also have\n",
    "varying label sizes. As a result, we need to pad those labels to the same size.\n",
    "To deal with this problem, GluonCV provides :py:class:`gluoncv.data.batchify.Pad`,\n",
    "which handles padding automatically.\n",
    ":py:class:`gluoncv.data.batchify.Stack` in addition, is used to stack NDArrays with consistent shapes.\n",
    ":py:class:`gluoncv.data.batchify.Tuple` is used to handle different behaviors across multiple outputs from transform functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "from mxnet.gluon.data import DataLoader\n",
    "\n",
    "batch_size = 2  # for tutorial, we use smaller batch-size\n",
    "num_workers = 0  # you can make it larger(if your CPU has more cores) to accelerate data loading\n",
    "\n",
    "# behavior of batchify_fn: stack images, and pad labels\n",
    "batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "#batchify_fn = Tuple(*([Stack() for _ in range(6)] + [Pad(axis=0, pad_val=-1) for _ in range(1)]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset.transform(train_transform), batch_size, shuffle=True,\n",
    "                          batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset.transform(val_transform), batch_size, shuffle=False,\n",
    "                        batchify_fn=batchify_fn, last_batch='keep', num_workers=num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (2, 3, 416, 416) (2, 2, 6)\n",
      "data 0: (3, 416, 416) label 0: (2, 6) \n",
      "[[  0.   0. 416. 416.  17.   0.]\n",
      " [ -1.  -1.  -1.  -1.  -1.  -1.]]\n",
      "<NDArray 2x6 @cpu_shared(0)>\n",
      "data 1: (3, 416, 416) label 1: (2, 6) \n",
      "[[ 38.953182 167.14285  208.7491   304.57144    1.         0.      ]\n",
      " [ 38.953182   0.       208.7491   304.57144   14.         0.      ]]\n",
      "<NDArray 2x6 @cpu_shared(0)>\n",
      "2 (2, 3, 416, 416) (2, 12, 6)\n",
      "data 0: (3, 416, 416) label 0: (12, 6) \n",
      "[[303.54678 135.59277 315.5862  178.28572  14.        0.     ]\n",
      " [249.24138 140.71593 259.74384 174.52873  14.        0.     ]\n",
      " [233.10345 142.42365 242.58128 172.47948  14.        0.     ]\n",
      " [219.5271  141.39902 225.93103 170.08867  14.        0.     ]\n",
      " [264.867   139.00821 274.34482 173.5041   14.        0.     ]\n",
      " [289.45813 161.55008 293.55664 177.94417  14.        0.     ]\n",
      " [345.55664 160.18391 347.34976 182.72578  14.        1.     ]\n",
      " [293.3005  148.91298 334.79803 201.85222  12.        0.     ]\n",
      " [241.04434 152.3284  271.5271  193.65517  12.        0.     ]\n",
      " [220.03941 156.08539 235.66502 189.8982   12.        1.     ]\n",
      " [264.61084 153.01149 287.66504 192.97209  12.        0.     ]\n",
      " [234.89655 156.08539 247.70444 188.19048  12.        1.     ]]\n",
      "<NDArray 12x6 @cpu_shared(0)>\n",
      "data 1: (3, 416, 416) label 1: (12, 6) \n",
      "[[  0.      179.83849 255.1628  399.69595  14.        0.     ]\n",
      " [142.69768 170.94537 409.9535  398.70782  14.        0.     ]\n",
      " [ -1.       -1.       -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.       -1.       -1.     ]]\n",
      "<NDArray 12x6 @cpu_shared(0)>\n",
      "2 (2, 3, 416, 416) (2, 3, 6)\n",
      "data 0: (3, 416, 416) label 0: (3, 6) \n",
      "[[  0.        0.      279.64444 416.       15.        0.     ]\n",
      " [ -1.       -1.       -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.       -1.       -1.     ]]\n",
      "<NDArray 3x6 @cpu_shared(0)>\n",
      "data 1: (3, 416, 416) label 1: (3, 6) \n",
      "[[139.93593   88.027306 245.60184  278.27988    3.         0.      ]\n",
      " [  0.       198.77133   88.53089  264.0819     3.         0.      ]\n",
      " [300.81464  102.22526  416.       279.69965    3.         0.      ]]\n",
      "<NDArray 3x6 @cpu_shared(0)>\n",
      "2 (2, 3, 416, 416) (2, 2, 6)\n",
      "data 0: (3, 416, 416) label 0: (2, 6) \n",
      "[[  0.      135.93701 295.90475 416.       16.        0.     ]\n",
      " [107.71429   0.      416.      416.       14.        0.     ]]\n",
      "<NDArray 2x6 @cpu_shared(0)>\n",
      "data 1: (3, 416, 416) label 1: (2, 6) \n",
      "[[  0.          0.        416.        416.         14.          0.       ]\n",
      " [  1.2959502   0.        251.41434   416.          2.          0.       ]]\n",
      "<NDArray 2x6 @cpu_shared(0)>\n"
     ]
    }
   ],
   "source": [
    "for ib, batch in enumerate(train_loader):\n",
    "    if ib > 3:\n",
    "        break\n",
    "    print(len(batch), batch[0].shape, batch[1].shape)\n",
    "    print('data 0:', batch[0][0].shape, 'label 0:', batch[1][0].shape, batch[1][0])\n",
    "    print('data 1:', batch[0][1].shape, 'label 1:', batch[1][1].shape, batch[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOv3 Network\n",
    "-------------------\n",
    "GluonCV's YOLOv3 implementation is a composite Gluon HybridBlock.\n",
    "In terms of structure, YOLOv3 networks are composed of base feature extraction\n",
    "network, convolutional transition layers, upsampling layers, and specially designed YOLOv3 output layers.\n",
    "\n",
    "We highly recommend you to read the original paper to learn more about the ideas\n",
    "behind YOLO [YOLOv3]_.\n",
    "\n",
    "`Gluon Model Zoo <../../model_zoo/index.html>`__ has a few built-in YOLO networks, more on the way.\n",
    "You can load your favorite one with one simple line of code:\n",
    "\n",
    ".. hint::\n",
    "\n",
    "   To avoid downloading models in this tutorial, we set `pretrained_base=False`,\n",
    "   in practice we usually want to load pre-trained imagenet models by setting\n",
    "   `pretrained_base=True`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOV3(\n",
      "  (_target_generator): YOLOV3TargetMerger(\n",
      "    (_dynamic_target): YOLOV3DynamicTargetGeneratorSimple(\n",
      "      (_batch_iou): BBoxBatchIOU(\n",
      "        (_pre): BBoxSplit(\n",
      "        \n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_loss): YOLOV3Loss(batch_axis=0, w=None)\n",
      "  (stages): HybridSequential(\n",
      "    (0): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(None -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (2): LeakyReLU(0.1)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(None -> 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (2): LeakyReLU(0.1)\n",
      "      )\n",
      "      (2): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): HybridSequential(\n",
      "        (0): Conv2D(None -> 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (2): LeakyReLU(0.1)\n",
      "      )\n",
      "      (4): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): HybridSequential(\n",
      "        (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (2): LeakyReLU(0.1)\n",
      "      )\n",
      "      (7): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (2): LeakyReLU(0.1)\n",
      "      )\n",
      "      (1): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(None -> 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (2): LeakyReLU(0.1)\n",
      "      )\n",
      "      (1): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): DarknetBasicBlockV3(\n",
      "        (body): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(None -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "          (1): HybridSequential(\n",
      "            (0): Conv2D(None -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "            (2): LeakyReLU(0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (transitions): HybridSequential(\n",
      "    (0): HybridSequential(\n",
      "      (0): Conv2D(None -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "      (2): LeakyReLU(0.1)\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): Conv2D(None -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "      (2): LeakyReLU(0.1)\n",
      "    )\n",
      "  )\n",
      "  (yolo_blocks): HybridSequential(\n",
      "    (0): YOLODetectionBlockV3(\n",
      "      (body): HybridSequential(\n",
      "        (0): HybridSequential(\n",
      "          (0): Conv2D(None -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "        (1): HybridSequential(\n",
      "          (0): Conv2D(None -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "        (2): HybridSequential(\n",
      "          (0): Conv2D(None -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "        (3): HybridSequential(\n",
      "          (0): Conv2D(None -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "        (4): HybridSequential(\n",
      "          (0): Conv2D(None -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "      )\n",
      "      (tip): HybridSequential(\n",
      "        (0): Conv2D(None -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (2): LeakyReLU(0.1)\n",
      "      )\n",
      "    )\n",
      "    (1): YOLODetectionBlockV3(\n",
      "      (body): HybridSequential(\n",
      "        (0): HybridSequential(\n",
      "          (0): Conv2D(None -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "        (1): HybridSequential(\n",
      "          (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "        (2): HybridSequential(\n",
      "          (0): Conv2D(None -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "        (3): HybridSequential(\n",
      "          (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "        (4): HybridSequential(\n",
      "          (0): Conv2D(None -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "      )\n",
      "      (tip): HybridSequential(\n",
      "        (0): Conv2D(None -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (2): LeakyReLU(0.1)\n",
      "      )\n",
      "    )\n",
      "    (2): YOLODetectionBlockV3(\n",
      "      (body): HybridSequential(\n",
      "        (0): HybridSequential(\n",
      "          (0): Conv2D(None -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "        (1): HybridSequential(\n",
      "          (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "        (2): HybridSequential(\n",
      "          (0): Conv2D(None -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "        (3): HybridSequential(\n",
      "          (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "        (4): HybridSequential(\n",
      "          (0): Conv2D(None -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "          (2): LeakyReLU(0.1)\n",
      "        )\n",
      "      )\n",
      "      (tip): HybridSequential(\n",
      "        (0): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
      "        (2): LeakyReLU(0.1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (yolo_outputs): HybridSequential(\n",
      "    (0): YOLOOutputV3(\n",
      "      (prediction): Conv2D(None -> 75, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): YOLOOutputV3(\n",
      "      (prediction): Conv2D(None -> 75, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): YOLOOutputV3(\n",
      "      (prediction): Conv2D(None -> 75, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from gluoncv import model_zoo\n",
    "net = model_zoo.get_model('yolo3_darknet53_voc', pretrained_base=False)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOv3 network is callable with image tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "x = mx.nd.zeros(shape=(1, 3, 416, 416))\n",
    "net.initialize()\n",
    "cids, scores, bboxes = net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOv3 returns three values, where ``cids`` are the class labels,\n",
    "``scores`` are confidence scores of each prediction,\n",
    "and ``bboxes`` are absolute coordinates of corresponding bounding boxes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training targets\n",
    "----------------\n",
    "There are four losses involved in end-to-end YOLOv3 training.\n",
    "the loss to penalize incorrect class/box prediction, and is defined in :py:class:`gluoncv.loss.YOLOV3Loss`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gcv.loss.YOLOV3Loss()\n",
    "# which is already included in YOLOv3 network\n",
    "print(net._loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up training, we let CPU to pre-compute some training targets (similar to SSD example).\n",
    "This is especially nice when your CPU is powerful and you can use ``-j num_workers``\n",
    "to utilize multi-core CPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we provide network to the training transform function, it will compute partial training targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd\n",
    "train_transform = presets.yolo.YOLO3DefaultTrainTransform(width, height, net)\n",
    "# return stacked images, center_targets, scale_targets, gradient weights, objectness_targets, class_targets\n",
    "# additionally, return padded ground truth bboxes, so there are 7 components returned by dataloader\n",
    "batchify_fn = Tuple(*([Stack() for _ in range(6)] + [Pad(axis=0, pad_val=-1) for _ in range(1)]))\n",
    "train_loader = DataLoader(train_dataset.transform(train_transform), batch_size, shuffle=True,\n",
    "                          batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 7\n",
      "data[0]: (2, 3, 416, 416)\n",
      "data: (3, 416, 416)\n",
      "label1: (10647, 1)\n",
      "label2: (10647, 2)\n",
      "label3: (10647, 2)\n",
      "label4: (10647, 2)\n",
      "label5: (10647, 20)\n",
      "label6: (13, 4)\n",
      "label6: \n",
      "[[163.60672 216.97842 251.39569 291.05035]\n",
      " [189.54436 184.05756 220.47002 251.39569]\n",
      " [ -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.     ]\n",
      " [ -1.       -1.       -1.       -1.     ]]\n",
      "<NDArray 13x4 @cpu_shared(0)>\n"
     ]
    }
   ],
   "source": [
    "batchimg = []\n",
    "blabel = []\n",
    "for ib, batch in enumerate(train_loader):\n",
    "    if ib > 0:\n",
    "        break\n",
    "    \n",
    "    print('batch:', len(batch))\n",
    "    print('data[0]:', batch[0].shape)\n",
    "    print('data:', batch[0][0].shape)\n",
    "    batchimg = batch[0][0]\n",
    "    blabel = batch\n",
    "    print('label1:', batch[1][0].shape)\n",
    "    print('label2:', batch[2][0].shape)\n",
    "    print('label3:', batch[3][0].shape)\n",
    "    print('label4:', batch[4][0].shape)\n",
    "    print('label5:', batch[5][0].shape)\n",
    "    print('label6:', batch[6][0].shape)\n",
    "    print('label6:', batch[6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image2 = train_image2.transpose((1, 2, 0)) * nd.array((0.229, 0.224, 0.225)) + nd.array((0.485, 0.456, 0.406))\n",
    "train_image2 = (train_image2 * 255).clip(0, 255)\n",
    "ax = viz.plot_bbox(train_image2.asnumpy(), train_label2[:, :4],\n",
    "                   labels=train_label2[:, 4:5],\n",
    "                   class_names=train_dataset.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = batchimg.transpose((1,2,0)) * nd.array((0.229,0.224,0.225)) + nd.array((0.485,0.456,0.406))\n",
    "img = (img * 255).clip(0,255)\n",
    "\n",
    "ax = viz.plot_bbox(img.asnumpy(), train_label[:, :4],\n",
    "                   labels=train_label[:, 4:5],\n",
    "                   class_names=train_dataset.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ib, batch in enumerate(train_loader):\n",
    "    if ib > 0:\n",
    "        break\n",
    "    print('data:', batch[0][0].shape)\n",
    "    print('label:', batch[6][0].shape)\n",
    "    with autograd.record():\n",
    "        input_order = [0, 6, 1, 2, 3, 4, 5]\n",
    "        obj_loss, center_loss, scale_loss, cls_loss = net(*[batch[o] for o in input_order])\n",
    "        # sum up the losses\n",
    "        # some standard gluon training steps:\n",
    "        # autograd.backward(sum_loss)\n",
    "        # trainer.step(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we can see the data loader is actually returning the training targets for us.\n",
    "Then it is very naturally a gluon training loop with Trainer and let it update the weights.\n",
    "\n",
    ".. hint::\n",
    "\n",
    "  Please checkout the full :download:`training script <../../../scripts/detection/yolo/train_yolo3.py>` for complete implementation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "----------\n",
    "\n",
    ".. [YOLOv3] Redmon, Joseph, and Ali Farhadi. \"Yolov3: An incremental improvement.\" arXiv preprint arXiv:1804.02767 (2018).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
